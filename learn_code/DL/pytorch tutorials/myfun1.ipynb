{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-3-98026b652870>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-98026b652870>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    model = nn.Sequential(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# inputs = torch.rand(64, 3, 244, 244)\n",
    "# conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "# out = conv(inputs)\n",
    "\n",
    "# # Example of using Sequential\n",
    "#         model = nn.Sequential(\n",
    "#                   nn.Conv2d(1,20,5),\n",
    "#                   nn.ReLU(),\n",
    "#                   nn.Conv2d(20,64,5),\n",
    "#                   nn.ReLU()\n",
    "#                 )\n",
    "\n",
    "#         # Example of using Sequential with OrderedDict\n",
    "#         model = nn.Sequential(OrderedDict([\n",
    "#                   ('conv1', nn.Conv2d(1,20,5)),\n",
    "#                   ('relu1', nn.ReLU()),\n",
    "#                   ('conv2', nn.Conv2d(20,64,5)),\n",
    "#                   ('relu2', nn.ReLU())\n",
    "#                 ]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ad9e8313ed39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "#https://blog.csdn.net/dss_dssssd/article/details/82980222\n",
    "\n",
    "# hyper parameters\n",
    "in_dim=1\n",
    "n_hidden_1=1\n",
    "n_hidden_2=1\n",
    "out_dim=1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, n_hidden_1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(n_hidden_1, n_hidden_2),\n",
    "            nn.ReLU(True),\n",
    "            # 最后一层不需要添加激活函数\n",
    "            nn.Linear(n_hidden_2, out_dim)\n",
    "             )\n",
    "\n",
    "    def forward(self, x):\n",
    "      \tx = self.layer(x)\n",
    "      \treturn  print(x)\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn与nn.function 区别\n",
    "#1.nn\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(in_channels=1,  out_channels=16, kernel_size=5,padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5,  padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.linear1 = nn.Linear(4 * 4 * 32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.maxpool1(self.relu1(self.cnn1(x)))\n",
    "        out = self.maxpool2(self.relu2(self.cnn2(out)))\n",
    "        out = self.linear1(out.view(x.size(0), -1))\n",
    "        return out\n",
    "    \n",
    "#2.nn.function  作用同上\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.cnn1_weight = nn.Parameter(torch.rand(16, 1, 5, 5))\n",
    "        self.bias1_weight = nn.Parameter(torch.rand(16))\n",
    "        \n",
    "        self.cnn2_weight = nn.Parameter(torch.rand(32, 16, 5, 5))\n",
    "        self.bias2_weight = nn.Parameter(torch.rand(32))\n",
    "        \n",
    "        self.linear1_weight = nn.Parameter(torch.rand(4 * 4 * 32, 10))\n",
    "        self.bias3_weight = nn.Parameter(torch.rand(10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = F.conv2d(x, self.cnn1_weight, self.bias1_weight)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out)\n",
    "        \n",
    "        out = F.conv2d(x, self.cnn2_weight, self.bias2_weight)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out)\n",
    "        \n",
    "        out = F.linear(x, self.linear1_weight, self.bias3_weight)\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6745, 0.0000, 0.0000, 0.0000, 0.0000, 0.5155, 0.6657, 0.0000, 1.5495,\n",
      "        0.0000])\n",
      "tensor([0.0000, 0.4281, 0.0000, 0.0000, 0.0000, 0.0000, 0.6657, 1.7418, 0.0000,\n",
      "        1.6574])\n",
      "--------------------eval model:--------------------\r\n",
      "\n",
      "tensor([0.3373, 0.2141, 0.8412, 0.0870, 0.2735, 0.2577, 0.3328, 0.8709, 0.7747,\n",
      "        0.8287])\n",
      "tensor([0.0000, 0.4281, 0.0000, 0.0000, 0.5470, 0.0000, 0.6657, 0.0000, 1.5495,\n",
      "        0.0000])\n"
     ]
    }
   ],
   "source": [
    "#使用nn.Xxx方式定义dropout，在调用model.eval()之后，\n",
    "#model中所有的dropout layer都关闭，但以nn.function.dropout方式定义dropout，\n",
    "#在调用model.eval()之后并不能关闭dropout。\n",
    "\n",
    "#区别\n",
    "#1.在定义函数层（继承nn.Module）时，init函数中应该用torch.nn,\n",
    "#  例如torch.nn.ReLU，torch.nn.Dropout2d,而forward中应该用torch.nn.functionl,\n",
    "#   例如torch.nn.functional.relu,不过请注意，init里面定义的是标准的网络层。\n",
    "#   只有torch.nn定义的才会进行训练。torch.nn.functional定义的需要自己手动设置参数。\n",
    "#    所以通常，激活函数或者卷积之类的都用torch.nn定义。\n",
    "#2.torch.nn是类，必须要先在init中实例化，然后在forward中使用，\n",
    "#   而torch.nn.functional可以直接在forward中使用。\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "class Model2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.dropout(x)\n",
    "\n",
    "#help dropout\n",
    "class Model3(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model3, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.dropout(x, training=self.training)\n",
    "\n",
    "\n",
    "m1 = Model1()\n",
    "m2 = Model2()\n",
    "inputs = torch.rand(10)\n",
    "print(m1(inputs))\n",
    "print(m2(inputs))\n",
    "print(20 * '-' + \"eval model:\" + 20 * '-' + '\\r\\n')\n",
    "m1.eval()\n",
    "m2.eval()\n",
    "print(m1(inputs))\n",
    "print(m2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a30ad87eaa02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m transform = transforms.Compose(\n\u001b[0m\u001b[1;32m      2\u001b[0m     [transforms.ToTensor(),\n\u001b[1;32m      3\u001b[0m      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fa128141eebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# functions to show an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m transform = transforms.Compose(\n\u001b[0m\u001b[1;32m      7\u001b[0m     [transforms.ToTensor(),\n\u001b[1;32m      8\u001b[0m      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger_error\n",
      "b.grad_fn = <CopySlices object at 0x7f70390843c8>. \n",
      "a.grad = tensor([5.]). \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    " \n",
    "def trigger_error():\n",
    "    print(\"trigger_error\")\n",
    "    \n",
    "    # Tensors.\n",
    "    a = torch.tensor([1.0], requires_grad=True)\n",
    "#error    b = torch.zeros((2), requires_grad=True)\n",
    "    b = torch.zeros((2),requires_grad=False) #2\n",
    "#error # CopySlices.\n",
    "    b[0] = a*2  #2\n",
    "    b[1] = a*3  #2\n",
    " #如果我们只有确定个数的元素需要组成一个新的tensor，\n",
    " #可以使用torch.cat()函数\n",
    "    # 1 b = torch.cat((a*2,a*3))\n",
    "    \n",
    "    print(\"b.grad_fn = {}. \".format(b.grad_fn))\n",
    " \n",
    "    # Trigger an error.\n",
    "    b.backward(torch.ones((2)))\n",
    " \n",
    "    print(\"a.grad = {}. \".format( a.grad ))\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    trigger_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1): seq[0]=h\n",
      "(1): seq[1]=e\n",
      "(1): seq[2]=l\n",
      "(1): seq[3]=l\n",
      "(1): seq[4]=o\n",
      "(2): seq2[0]=a\n",
      "(2): seq2[1]=b\n",
      "(2): seq2[2]=c\n",
      "(2): seq2[3]=d\n"
     ]
    }
   ],
   "source": [
    "seq = 'hello'\n",
    "for i,key in enumerate(seq):\n",
    "    print('(1):','seq[%d]=%s'%(i,key))\n",
    "seq2 = ['a','b','c','d']\n",
    "for i,key in enumerate(seq2):\n",
    "    print('(2):','seq2[%d]=%s'%(i,key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27761836.0\n",
      "1 23844970.0\n",
      "2 23342338.0\n",
      "3 23030470.0\n",
      "4 20974156.0\n",
      "5 16869134.0\n",
      "6 11884099.0\n",
      "7 7553445.5\n",
      "8 4546211.0\n",
      "9 2730724.0\n",
      "10 1707507.25\n",
      "11 1138280.5\n",
      "12 813087.625\n",
      "13 617230.75\n",
      "14 490821.34375\n",
      "15 403333.65625\n",
      "16 338967.125\n",
      "17 289158.71875\n",
      "18 249203.03125\n",
      "19 216410.703125\n",
      "20 189001.71875\n",
      "21 165815.34375\n",
      "22 146067.3125\n",
      "23 129115.4375\n",
      "24 114483.3671875\n",
      "25 101796.3984375\n",
      "26 90760.640625\n",
      "27 81119.7265625\n",
      "28 72667.53125\n",
      "29 65236.1484375\n",
      "30 58682.58984375\n",
      "31 52884.92578125\n",
      "32 47744.80859375\n",
      "33 43178.86328125\n",
      "34 39112.578125\n",
      "35 35483.2265625\n",
      "36 32237.24609375\n",
      "37 29329.728515625\n",
      "38 26719.185546875\n",
      "39 24371.0546875\n",
      "40 22256.21875\n",
      "41 20346.951171875\n",
      "42 18622.3203125\n",
      "43 17061.654296875\n",
      "44 15647.3779296875\n",
      "45 14364.431640625\n",
      "46 13198.7490234375\n",
      "47 12138.53515625\n",
      "48 11173.1494140625\n",
      "49 10293.0400390625\n",
      "50 9489.66796875\n",
      "51 8756.0458984375\n",
      "52 8084.66259765625\n",
      "53 7469.7978515625\n",
      "54 6906.62255859375\n",
      "55 6390.08642578125\n",
      "56 5916.1806640625\n",
      "57 5480.4501953125\n",
      "58 5079.76953125\n",
      "59 4711.16015625\n",
      "60 4371.6357421875\n",
      "61 4058.73095703125\n",
      "62 3770.087158203125\n",
      "63 3503.81591796875\n",
      "64 3258.17578125\n",
      "65 3031.077392578125\n",
      "66 2821.038330078125\n",
      "67 2626.706298828125\n",
      "68 2446.809814453125\n",
      "69 2280.097412109375\n",
      "70 2125.651611328125\n",
      "71 1982.3963623046875\n",
      "72 1849.509521484375\n",
      "73 1726.1444091796875\n",
      "74 1611.634033203125\n",
      "75 1505.2274169921875\n",
      "76 1406.2537841796875\n",
      "77 1314.2159423828125\n",
      "78 1228.5958251953125\n",
      "79 1149.169677734375\n",
      "80 1075.2587890625\n",
      "81 1006.4012451171875\n",
      "82 942.2154541015625\n",
      "83 882.424560546875\n",
      "84 826.6383056640625\n",
      "85 774.6187744140625\n",
      "86 726.005615234375\n",
      "87 680.6135864257812\n",
      "88 638.2147827148438\n",
      "89 598.5953369140625\n",
      "90 561.5692138671875\n",
      "91 526.9449462890625\n",
      "92 494.56805419921875\n",
      "93 464.2777099609375\n",
      "94 435.9266052246094\n",
      "95 409.3974609375\n",
      "96 384.5563659667969\n",
      "97 361.298095703125\n",
      "98 339.4996643066406\n",
      "99 319.08099365234375\n",
      "100 299.94842529296875\n",
      "101 282.0137023925781\n",
      "102 265.18536376953125\n",
      "103 249.40606689453125\n",
      "104 234.60516357421875\n",
      "105 220.70994567871094\n",
      "106 207.67694091796875\n",
      "107 195.43954467773438\n",
      "108 183.95249938964844\n",
      "109 173.1643829345703\n",
      "110 163.03628540039062\n",
      "111 153.52552795410156\n",
      "112 144.58151245117188\n",
      "113 136.17724609375\n",
      "114 128.2761688232422\n",
      "115 120.85231018066406\n",
      "116 113.87358093261719\n",
      "117 107.30960845947266\n",
      "118 101.13443756103516\n",
      "119 95.3295669555664\n",
      "120 89.86888122558594\n",
      "121 84.72901153564453\n",
      "122 79.8893051147461\n",
      "123 75.33758544921875\n",
      "124 71.05364227294922\n",
      "125 67.021240234375\n",
      "126 63.22126388549805\n",
      "127 59.643280029296875\n",
      "128 56.27383804321289\n",
      "129 53.099727630615234\n",
      "130 50.110050201416016\n",
      "131 47.2928352355957\n",
      "132 44.63955307006836\n",
      "133 42.138214111328125\n",
      "134 39.7791748046875\n",
      "135 37.558040618896484\n",
      "136 35.463130950927734\n",
      "137 33.48778533935547\n",
      "138 31.626270294189453\n",
      "139 29.872159957885742\n",
      "140 28.216354370117188\n",
      "141 26.65413475036621\n",
      "142 25.181943893432617\n",
      "143 23.79421615600586\n",
      "144 22.484500885009766\n",
      "145 21.248111724853516\n",
      "146 20.081350326538086\n",
      "147 18.98113250732422\n",
      "148 17.94228172302246\n",
      "149 16.96149253845215\n",
      "150 16.035127639770508\n",
      "151 15.160985946655273\n",
      "152 14.335057258605957\n",
      "153 13.555781364440918\n",
      "154 12.819632530212402\n",
      "155 12.12426471710205\n",
      "156 11.467249870300293\n",
      "157 10.846588134765625\n",
      "158 10.260553359985352\n",
      "159 9.706960678100586\n",
      "160 9.183796882629395\n",
      "161 8.689188003540039\n",
      "162 8.221755027770996\n",
      "163 7.779817581176758\n",
      "164 7.36241340637207\n",
      "165 6.9674835205078125\n",
      "166 6.594949722290039\n",
      "167 6.242395401000977\n",
      "168 5.9093122482299805\n",
      "169 5.594114303588867\n",
      "170 5.295909881591797\n",
      "171 5.013869285583496\n",
      "172 4.747568130493164\n",
      "173 4.495156288146973\n",
      "174 4.256760597229004\n",
      "175 4.031191825866699\n",
      "176 3.8179612159729004\n",
      "177 3.616048812866211\n",
      "178 3.4250879287719727\n",
      "179 3.2445287704467773\n",
      "180 3.0733187198638916\n",
      "181 2.911668300628662\n",
      "182 2.7588038444519043\n",
      "183 2.6138622760772705\n",
      "184 2.4766793251037598\n",
      "185 2.3468856811523438\n",
      "186 2.2239325046539307\n",
      "187 2.10772967338562\n",
      "188 1.9974892139434814\n",
      "189 1.8934260606765747\n",
      "190 1.7946604490280151\n",
      "191 1.7012665271759033\n",
      "192 1.6127692461013794\n",
      "193 1.5290218591690063\n",
      "194 1.449500560760498\n",
      "195 1.3744686841964722\n",
      "196 1.3033665418624878\n",
      "197 1.235834002494812\n",
      "198 1.1720033884048462\n",
      "199 1.11151921749115\n",
      "200 1.0542157888412476\n",
      "201 0.9998647570610046\n",
      "202 0.9484603404998779\n",
      "203 0.8996865153312683\n",
      "204 0.8534100651741028\n",
      "205 0.8096435070037842\n",
      "206 0.7681402564048767\n",
      "207 0.7287937998771667\n",
      "208 0.6915821433067322\n",
      "209 0.6563212275505066\n",
      "210 0.6227647662162781\n",
      "211 0.5910736322402954\n",
      "212 0.5609203577041626\n",
      "213 0.5323425531387329\n",
      "214 0.5053219795227051\n",
      "215 0.47970861196517944\n",
      "216 0.45541346073150635\n",
      "217 0.4322558641433716\n",
      "218 0.4104510247707367\n",
      "219 0.3896609842777252\n",
      "220 0.3699781000614166\n",
      "221 0.35132670402526855\n",
      "222 0.3336319923400879\n",
      "223 0.3168541193008423\n",
      "224 0.3009607195854187\n",
      "225 0.2858075499534607\n",
      "226 0.2714233994483948\n",
      "227 0.25784847140312195\n",
      "228 0.2449343055486679\n",
      "229 0.23262450098991394\n",
      "230 0.22105209529399872\n",
      "231 0.2099916636943817\n",
      "232 0.19958290457725525\n",
      "233 0.1896350234746933\n",
      "234 0.18018464744091034\n",
      "235 0.17123892903327942\n",
      "236 0.16273489594459534\n",
      "237 0.15463000535964966\n",
      "238 0.1470271795988083\n",
      "239 0.13972212374210358\n",
      "240 0.1328517496585846\n",
      "241 0.12630648910999298\n",
      "242 0.12008556723594666\n",
      "243 0.11413532495498657\n",
      "244 0.10849344730377197\n",
      "245 0.10318952798843384\n",
      "246 0.09811016917228699\n",
      "247 0.09329447150230408\n",
      "248 0.08873089402914047\n",
      "249 0.08439980447292328\n",
      "250 0.0802808403968811\n",
      "251 0.0763581320643425\n",
      "252 0.07261938601732254\n",
      "253 0.06908135861158371\n",
      "254 0.06570320576429367\n",
      "255 0.06253860890865326\n",
      "256 0.0595063678920269\n",
      "257 0.056607913225889206\n",
      "258 0.05387182906270027\n",
      "259 0.0512651652097702\n",
      "260 0.048771925270557404\n",
      "261 0.04641662910580635\n",
      "262 0.04416390508413315\n",
      "263 0.04207264631986618\n",
      "264 0.04003555327653885\n",
      "265 0.03811514005064964\n",
      "266 0.03628409281373024\n",
      "267 0.03455200418829918\n",
      "268 0.03290747478604317\n",
      "269 0.03133657947182655\n",
      "270 0.029857445508241653\n",
      "271 0.02843543328344822\n",
      "272 0.027076788246631622\n",
      "273 0.025787999853491783\n",
      "274 0.02457200177013874\n",
      "275 0.023401988670229912\n",
      "276 0.02231011353433132\n",
      "277 0.021267857402563095\n",
      "278 0.02025510184466839\n",
      "279 0.019305871799588203\n",
      "280 0.018405597656965256\n",
      "281 0.017553571611642838\n",
      "282 0.016726724803447723\n",
      "283 0.015949759632349014\n",
      "284 0.015207190066576004\n",
      "285 0.014502914622426033\n",
      "286 0.013825591653585434\n",
      "287 0.01319094467908144\n",
      "288 0.012577793560922146\n",
      "289 0.011992808431386948\n",
      "290 0.011438516899943352\n",
      "291 0.010920110158622265\n",
      "292 0.010420256294310093\n",
      "293 0.009945633821189404\n",
      "294 0.009495812468230724\n",
      "295 0.00906823854893446\n",
      "296 0.008653971366584301\n",
      "297 0.008267701603472233\n",
      "298 0.007893996313214302\n",
      "299 0.00753728486597538\n",
      "300 0.007197152823209763\n",
      "301 0.006878593936562538\n",
      "302 0.0065722218714654446\n",
      "303 0.006286792457103729\n",
      "304 0.006007775664329529\n",
      "305 0.005741370376199484\n",
      "306 0.005495202727615833\n",
      "307 0.005248854868113995\n",
      "308 0.0050265127792954445\n",
      "309 0.004806507378816605\n",
      "310 0.004596047103404999\n",
      "311 0.004393246024847031\n",
      "312 0.004207853693515062\n",
      "313 0.004027349874377251\n",
      "314 0.0038573341444134712\n",
      "315 0.0036914001684635878\n",
      "316 0.003534774761646986\n",
      "317 0.00338732055388391\n",
      "318 0.0032459895592182875\n",
      "319 0.003110302612185478\n",
      "320 0.002981256227940321\n",
      "321 0.002856399631127715\n",
      "322 0.0027388199232518673\n",
      "323 0.002625510096549988\n",
      "324 0.0025206373538821936\n",
      "325 0.0024198340252041817\n",
      "326 0.002321094274520874\n",
      "327 0.002229569246992469\n",
      "328 0.002139829797670245\n",
      "329 0.0020545125007629395\n",
      "330 0.0019752972293645144\n",
      "331 0.001899402472190559\n",
      "332 0.0018236329779028893\n",
      "333 0.0017554109217599034\n",
      "334 0.0016882449854165316\n",
      "335 0.0016243273857980967\n",
      "336 0.0015606267843395472\n",
      "337 0.00150266382843256\n",
      "338 0.0014462696854025126\n",
      "339 0.0013934536837041378\n",
      "340 0.001343550393357873\n",
      "341 0.0012921920279040933\n",
      "342 0.0012464371975511312\n",
      "343 0.0012014955282211304\n",
      "344 0.0011594383977353573\n",
      "345 0.001117751351557672\n",
      "346 0.0010784973856061697\n",
      "347 0.0010435143485665321\n",
      "348 0.0010055212769657373\n",
      "349 0.0009695508633740246\n",
      "350 0.0009359060786664486\n",
      "351 0.0009039430879056454\n",
      "352 0.0008741900091990829\n",
      "353 0.0008445829735137522\n",
      "354 0.000818235392216593\n",
      "355 0.0007903088699094951\n",
      "356 0.0007643569842912257\n",
      "357 0.0007403821800835431\n",
      "358 0.0007158981752581894\n",
      "359 0.0006921989843249321\n",
      "360 0.0006703707622364163\n",
      "361 0.0006501111784018576\n",
      "362 0.0006298762746155262\n",
      "363 0.0006109087262302637\n",
      "364 0.0005917816888540983\n",
      "365 0.0005742519861087203\n",
      "366 0.0005549939814954996\n",
      "367 0.0005386440316215158\n",
      "368 0.0005222324980422854\n",
      "369 0.0005076272645965219\n",
      "370 0.0004928370472043753\n",
      "371 0.0004776535206474364\n",
      "372 0.0004646754532586783\n",
      "373 0.000450621620984748\n",
      "374 0.0004377627919893712\n",
      "375 0.00042556264088489115\n",
      "376 0.0004133829497732222\n",
      "377 0.00040248752338811755\n",
      "378 0.0003903220349457115\n",
      "379 0.0003802704159170389\n",
      "380 0.000370124849723652\n",
      "381 0.00035964345443062484\n",
      "382 0.0003503736515995115\n",
      "383 0.00034029752714559436\n",
      "384 0.00033172083203680813\n",
      "385 0.00032316858414560556\n",
      "386 0.00031564017990604043\n",
      "387 0.00030617573065683246\n",
      "388 0.00029856566106900573\n",
      "389 0.0002914344659075141\n",
      "390 0.00028331109206192195\n",
      "391 0.0002755003224592656\n",
      "392 0.00026921325479634106\n",
      "393 0.00026287222863174975\n",
      "394 0.000255587394349277\n",
      "395 0.0002497683744877577\n",
      "396 0.0002431664033792913\n",
      "397 0.00023696628340985626\n",
      "398 0.00023160959244705737\n",
      "399 0.00022666175209451467\n",
      "400 0.00022073445143178105\n",
      "401 0.00021562332403846085\n",
      "402 0.00021069713693577796\n",
      "403 0.00020573625806719065\n",
      "404 0.00020134274382144213\n",
      "405 0.00019674243230838329\n",
      "406 0.00019232839986216277\n",
      "407 0.00018802820704877377\n",
      "408 0.00018440865096636117\n",
      "409 0.0001800987374735996\n",
      "410 0.0001764103799359873\n",
      "411 0.00017270990065298975\n",
      "412 0.0001688152115093544\n",
      "413 0.00016530536231584847\n",
      "414 0.0001620711846044287\n",
      "415 0.00015856536629144102\n",
      "416 0.00015548730152659118\n",
      "417 0.00015198698383755982\n",
      "418 0.00014879614172969013\n",
      "419 0.00014538840332534164\n",
      "420 0.00014298954920377582\n",
      "421 0.0001399201573804021\n",
      "422 0.00013725407188758254\n",
      "423 0.0001342952746199444\n",
      "424 0.00013189564924687147\n",
      "425 0.00012961779430042952\n",
      "426 0.00012743553088512272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427 0.00012474517279770225\n",
      "428 0.00012221848010085523\n",
      "429 0.0001200796032208018\n",
      "430 0.00011778970656450838\n",
      "431 0.00011541908315848559\n",
      "432 0.0001137144718086347\n",
      "433 0.00011132928193546832\n",
      "434 0.0001090987934730947\n",
      "435 0.00010738719720393419\n",
      "436 0.00010553192987572402\n",
      "437 0.00010336026753066108\n",
      "438 0.00010164672130485997\n",
      "439 9.96988092083484e-05\n",
      "440 9.810032497625798e-05\n",
      "441 9.609281551092863e-05\n",
      "442 9.428361954633147e-05\n",
      "443 9.298945951741189e-05\n",
      "444 9.159750334220007e-05\n",
      "445 9.016311378218234e-05\n",
      "446 8.88054637471214e-05\n",
      "447 8.738310862099752e-05\n",
      "448 8.609439100837335e-05\n",
      "449 8.481464465148747e-05\n",
      "450 8.328721742145717e-05\n",
      "451 8.184666512534022e-05\n",
      "452 8.053946658037603e-05\n",
      "453 7.900767377577722e-05\n",
      "454 7.771814853185788e-05\n",
      "455 7.645118603250012e-05\n",
      "456 7.535493932664394e-05\n",
      "457 7.40291943657212e-05\n",
      "458 7.292174268513918e-05\n",
      "459 7.189624739112332e-05\n",
      "460 7.092976738931611e-05\n",
      "461 7.010394620010629e-05\n",
      "462 6.914208643138409e-05\n",
      "463 6.803491851314902e-05\n",
      "464 6.693548493785784e-05\n",
      "465 6.574995495611802e-05\n",
      "466 6.50992151349783e-05\n",
      "467 6.384943844750524e-05\n",
      "468 6.288242730079219e-05\n",
      "469 6.201234646141529e-05\n",
      "470 6.112825940363109e-05\n",
      "471 6.009589560562745e-05\n",
      "472 5.930789848207496e-05\n",
      "473 5.8535762946121395e-05\n",
      "474 5.78269682591781e-05\n",
      "475 5.6920925999293104e-05\n",
      "476 5.5877859267638996e-05\n",
      "477 5.5278254876611754e-05\n",
      "478 5.445243732538074e-05\n",
      "479 5.383792085922323e-05\n",
      "480 5.317223258316517e-05\n",
      "481 5.248208253760822e-05\n",
      "482 5.184094698051922e-05\n",
      "483 5.1143651944585145e-05\n",
      "484 5.040083487983793e-05\n",
      "485 4.994033224647865e-05\n",
      "486 4.9373589718015864e-05\n",
      "487 4.8510592023376375e-05\n",
      "488 4.773228647536598e-05\n",
      "489 4.7137553337961435e-05\n",
      "490 4.674190131481737e-05\n",
      "491 4.602089393301867e-05\n",
      "492 4.525227632257156e-05\n",
      "493 4.48074824817013e-05\n",
      "494 4.4304877519607544e-05\n",
      "495 4.3887914216611534e-05\n",
      "496 4.3401949369581416e-05\n",
      "497 4.259014895069413e-05\n",
      "498 4.2117611883440986e-05\n",
      "499 4.1477476770523936e-05\n",
      "tensor([[ 2.1399,  1.8297, -1.1305,  ...,  0.1962, -0.0618, -1.0449],\n",
      "        [ 1.0102,  1.2508, -0.6922,  ...,  0.3989, -0.6635,  0.4563],\n",
      "        [ 0.8522, -0.2950, -0.6864,  ..., -0.3636, -0.8857,  1.7597],\n",
      "        ...,\n",
      "        [-1.0195,  0.3256,  2.4625,  ...,  1.5802, -0.3309,  0.2188],\n",
      "        [-0.8947, -1.0830,  0.6920,  ...,  2.3367,  1.0188,  1.1821],\n",
      "        [ 0.5881,  0.3610, -0.6787,  ...,  1.5051, -0.3142, -2.6148]]) tensor([[ 4.3094e-01, -8.7227e-02, -2.1286e-01,  1.3959e+00,  5.4821e-01,\n",
      "          9.7373e-01, -7.2663e-01, -6.2554e-02,  7.7809e-01,  3.6116e-01],\n",
      "        [ 2.1653e+00, -2.8020e-01, -8.6150e-01, -1.4242e-03,  2.9299e-03,\n",
      "         -4.1107e-01,  8.5780e-02, -4.9377e-01, -3.4890e-01, -1.9580e-01],\n",
      "        [ 1.9441e-01, -7.6909e-01, -7.6339e-01, -6.3361e-01,  2.7802e-01,\n",
      "          1.3600e+00, -5.3834e-01,  5.8530e-01,  2.4843e-01,  3.3322e-01],\n",
      "        [ 3.6445e-01, -1.0025e+00, -6.7665e-01,  2.0610e-01,  9.0782e-01,\n",
      "         -2.5696e-01, -9.3243e-03,  7.9157e-01,  1.8124e+00,  4.0039e-01],\n",
      "        [ 1.9886e-01,  1.4576e+00, -2.7084e-01, -8.2907e-02, -7.7430e-02,\n",
      "          4.3316e-01, -1.5817e-01, -1.3379e-01,  1.4591e-01, -2.9943e-02],\n",
      "        [ 1.6276e+00, -2.7904e-01,  1.0075e+00, -2.3453e+00,  6.4991e-01,\n",
      "          1.1055e+00, -1.0385e-01, -2.0992e+00, -5.8261e-01, -4.3720e-01],\n",
      "        [-1.6028e-01, -3.6787e-01,  3.5549e-02, -6.1673e-02,  1.4522e+00,\n",
      "          1.1257e+00,  6.7160e-01, -2.6339e+00,  9.0246e-01,  5.5701e-01],\n",
      "        [-1.3272e-01,  4.9687e-01,  2.1295e-01, -1.8485e+00, -1.4266e+00,\n",
      "         -5.4522e-01, -7.0564e-01,  2.9628e-01,  3.2242e-01,  9.9050e-01],\n",
      "        [ 3.1926e-01,  1.5585e-01,  1.5949e+00,  1.0302e+00,  4.3923e-01,\n",
      "          6.0359e-01, -1.3436e+00,  6.7029e-02, -1.0682e+00,  3.7318e-01],\n",
      "        [-1.0989e+00, -2.5755e-01, -8.0011e-01, -1.1464e+00, -3.2588e-01,\n",
      "          1.3351e+00,  4.5859e-01,  6.4541e-01, -2.3127e-01, -9.4517e-01],\n",
      "        [ 5.1226e-02,  6.1389e-01,  1.0110e+00,  1.3254e-01,  8.2083e-02,\n",
      "          5.9140e-01, -5.5772e-01,  5.0273e-01,  2.5656e-01, -4.7644e-01],\n",
      "        [-7.5820e-01, -6.0287e-01,  3.8690e-01,  1.7491e-01, -5.7489e-01,\n",
      "         -6.3075e-01, -1.1743e+00,  1.8167e-01,  4.5073e-01, -8.0139e-01],\n",
      "        [-5.2154e-01,  2.1945e+00,  1.9082e+00, -1.9347e-01,  6.4584e-01,\n",
      "          1.0790e+00, -1.0154e+00,  1.2674e+00,  4.9882e-01,  4.8579e-01],\n",
      "        [ 3.9273e-01, -1.1385e+00,  5.2128e-01, -1.1804e-01, -1.8165e+00,\n",
      "          1.4336e+00, -7.7173e-01,  8.5179e-02, -7.0240e-03, -1.8327e-01],\n",
      "        [-5.9646e-01,  1.5584e+00,  6.2321e-03, -5.7893e-01,  3.8445e-01,\n",
      "         -5.4224e-01,  1.2925e+00, -9.1480e-01,  1.1228e+00,  4.4061e-01],\n",
      "        [-2.9453e-01,  2.7609e-02, -1.9186e+00, -6.6714e-01, -6.9376e-01,\n",
      "         -1.2982e+00, -4.6915e-01, -1.0171e+00,  4.7120e-01, -1.2051e+00],\n",
      "        [ 2.1382e-01,  6.1146e-02,  4.1750e-01, -4.5085e-01,  1.3215e-01,\n",
      "         -5.2687e-01, -2.7621e-01, -7.2713e-02,  9.5714e-01, -6.7686e-01],\n",
      "        [-4.2870e-01,  6.1217e-01,  5.5825e-01,  4.5105e-01, -7.5432e-01,\n",
      "          1.0812e+00, -1.8506e+00,  2.5713e-01, -8.0705e-01, -7.9319e-01],\n",
      "        [-4.6797e-01, -8.8963e-02,  8.7176e-01,  2.4292e-01, -7.1266e-01,\n",
      "          7.2187e-01, -5.2702e-03,  1.3668e+00,  3.5033e-01,  5.6971e-01],\n",
      "        [ 8.1912e-01,  1.0970e+00,  1.7709e+00, -1.6470e-01,  4.6912e-01,\n",
      "          8.0298e-01, -1.7877e-01, -7.1897e-01, -6.6457e-01, -1.6513e+00],\n",
      "        [ 2.2502e-01, -7.8875e-01, -6.8677e-02,  6.1249e-01,  7.3361e-01,\n",
      "         -9.3973e-01, -8.1996e-01,  4.5479e-01, -3.3026e-01,  1.0468e+00],\n",
      "        [-7.1225e-01, -1.9972e+00, -7.5789e-01, -1.3612e+00, -1.1463e-01,\n",
      "         -4.0421e-02,  6.2819e-02, -1.5533e-01,  9.4880e-01,  3.0427e-01],\n",
      "        [-1.3759e+00, -8.5145e-01,  1.0246e+00,  2.0035e-01, -6.2390e-01,\n",
      "          1.3219e+00,  5.1165e-01,  8.3924e-01,  2.8788e-01,  4.9235e-03],\n",
      "        [-7.7913e-02, -6.4202e-02, -2.0315e-01,  9.0894e-01,  9.2558e-02,\n",
      "         -2.8963e-01,  1.1048e+00,  5.6914e-02, -1.6261e-01, -4.3236e-01],\n",
      "        [ 5.2017e-02, -5.0411e-01,  6.9481e-01,  9.5174e-01, -3.6957e-01,\n",
      "         -6.4223e-02, -4.0907e-01, -7.4944e-01, -8.8791e-02,  4.7531e-01],\n",
      "        [-1.0090e+00,  1.4209e+00, -1.7609e+00,  1.5170e+00,  3.8728e-02,\n",
      "          4.0620e-01, -6.8511e-01,  6.7234e-01,  7.4934e-01, -7.5453e-01],\n",
      "        [-1.3850e-01, -5.4186e-01,  1.6766e+00, -1.4636e+00, -4.8588e-01,\n",
      "          4.4024e-01, -2.4399e-01, -8.0368e-01,  5.2518e-01,  1.1323e+00],\n",
      "        [ 9.4045e-02,  1.3136e+00, -7.2116e-01,  1.3051e+00, -8.5910e-02,\n",
      "         -2.1558e-02, -3.3919e-01,  5.4436e-01, -1.3816e-01,  1.3437e+00],\n",
      "        [-1.2496e+00, -2.2507e-01, -1.6061e+00,  7.6382e-01, -2.9646e+00,\n",
      "         -7.7554e-02,  9.9712e-01,  3.0406e-01, -3.0085e-01, -1.4200e+00],\n",
      "        [ 8.6628e-01, -3.7474e-01, -1.0667e+00, -7.5699e-02,  4.7517e-01,\n",
      "         -7.7851e-01,  4.7929e-01,  4.9398e-01, -1.1615e+00,  9.9837e-01],\n",
      "        [-1.5304e-01,  1.5593e-01, -1.5675e+00,  7.1904e-01,  1.6711e+00,\n",
      "         -9.2300e-01,  8.2216e-01, -3.3035e-01,  5.9079e-01, -1.6588e+00],\n",
      "        [-6.5792e-01,  9.8276e-01,  7.2528e-01,  1.1546e+00,  4.7864e-01,\n",
      "          8.0698e-01,  1.5996e-01,  2.0287e+00,  2.9306e-01,  2.6427e-01],\n",
      "        [-5.2419e-01, -3.1095e-01, -4.8562e-01, -1.9290e-01, -1.8725e-01,\n",
      "          5.7657e-01, -1.9774e-02, -1.6829e+00,  3.4101e-01, -5.1044e-01],\n",
      "        [ 4.3509e-01,  9.6163e-01, -5.4195e-01,  2.8207e-01, -7.4811e-01,\n",
      "          6.3106e-01, -1.5328e-01,  7.1690e-01, -2.2670e-01, -4.1627e-01],\n",
      "        [ 1.0538e+00,  2.9556e-01,  3.5135e-01,  5.7775e-01, -1.5639e-01,\n",
      "         -2.0229e-01,  6.8775e-01,  1.2527e+00, -9.9520e-03, -1.0098e-01],\n",
      "        [-5.5021e-01,  2.6144e+00,  1.3862e-01,  1.0610e-01, -2.9234e-01,\n",
      "         -1.0068e-01,  7.2297e-01,  2.3531e+00, -4.5208e-02, -7.8932e-01],\n",
      "        [-9.3294e-01, -8.8089e-01, -2.0612e-01,  7.9900e-01, -2.1203e-01,\n",
      "         -3.6503e-02,  1.2170e+00,  6.1126e-01, -5.3762e-01,  3.7387e-02],\n",
      "        [ 1.0103e+00,  9.6828e-02,  3.5272e-01,  6.8347e-01,  1.8283e-01,\n",
      "         -2.5645e-01, -4.4124e-01,  5.0228e-02, -3.4149e-01, -1.2620e-01],\n",
      "        [ 3.3728e-01, -1.6097e-01, -1.1865e+00,  3.9551e-01,  3.7623e-01,\n",
      "          9.2899e-02,  1.5867e-01,  6.1278e-01, -6.3732e-02,  7.4743e-01],\n",
      "        [ 3.9229e-01, -2.9803e-01,  1.1490e+00, -6.3412e-01,  9.1775e-01,\n",
      "          4.0222e-01, -1.5118e+00, -1.0817e+00, -1.5387e-01,  4.1465e-01],\n",
      "        [-8.1895e-01, -7.4743e-01, -7.4350e-01,  2.7376e-01,  1.2145e+00,\n",
      "          9.2877e-02, -2.5905e-01,  4.2839e-01, -3.4403e-01,  1.5939e-01],\n",
      "        [-3.1385e-01, -1.1322e+00, -5.8713e-02, -1.2418e+00, -1.7285e+00,\n",
      "          1.0926e+00, -5.9795e-01,  1.0017e+00, -8.9102e-02,  1.5311e-01],\n",
      "        [ 1.9572e-01, -1.0410e+00, -8.7544e-01,  1.0767e+00,  2.7310e-01,\n",
      "         -7.4697e-01,  1.3314e+00, -3.4624e-02,  6.3188e-01,  1.2251e+00],\n",
      "        [ 6.0515e-01, -1.6740e+00,  4.2144e-01,  5.5480e-01,  3.5472e-01,\n",
      "         -4.4683e-01, -1.3384e+00, -3.5367e-01, -1.0092e+00, -5.4864e-01],\n",
      "        [ 1.4908e+00, -6.7547e-02,  8.5344e-01, -1.1293e+00,  2.4880e-01,\n",
      "          1.7638e+00,  2.0218e-01, -1.1222e-02, -2.6555e-01,  2.5748e-01],\n",
      "        [-1.3817e-01, -2.8845e-01, -9.6518e-01,  4.2764e-01,  6.8388e-01,\n",
      "          5.4182e-01, -1.1182e+00,  2.4903e-01, -1.0609e+00,  1.2120e+00],\n",
      "        [ 4.2759e-01, -2.6272e+00, -1.2030e+00,  1.4132e+00,  5.0506e-01,\n",
      "         -1.0479e+00, -9.7064e-01,  1.8620e-01, -5.8083e-01,  1.0049e-01],\n",
      "        [ 4.5803e-01,  1.5036e+00, -1.0836e+00, -1.1341e+00, -8.4372e-02,\n",
      "         -2.1109e-01,  3.1825e-01,  3.9042e-01, -3.3664e-01,  7.8408e-02],\n",
      "        [ 5.3309e-01,  1.4223e+00,  4.3764e-01, -9.5068e-01,  7.3962e-01,\n",
      "         -5.0754e-01, -8.5995e-01, -1.4388e+00,  2.8161e-01,  9.3331e-01],\n",
      "        [-9.8120e-02, -9.7765e-01, -3.4041e-01,  7.8941e-02,  8.2856e-01,\n",
      "         -3.7205e-01,  2.2607e-02,  3.6029e-01,  3.6709e-01, -1.1825e-01],\n",
      "        [-8.7312e-01,  5.7358e-01,  8.8661e-02,  1.3420e+00, -1.1727e+00,\n",
      "         -1.7421e+00,  9.4677e-01, -9.3314e-02, -1.5309e+00,  1.3437e-01],\n",
      "        [-8.6604e-01, -1.5825e+00,  9.3573e-01, -5.0529e-01, -1.3127e+00,\n",
      "          3.5795e-01, -3.6639e-01,  7.9153e-02, -6.1768e-01, -6.2379e-02],\n",
      "        [ 7.6736e-01,  4.5819e-01,  5.8719e-01,  1.2739e+00,  1.8065e-01,\n",
      "         -1.0265e+00, -3.2826e-01,  3.5791e-01, -6.8761e-01,  4.5152e-01],\n",
      "        [-1.6229e+00, -7.6851e-02,  1.7393e+00,  7.5497e-02,  3.9179e-02,\n",
      "          6.6141e-01, -2.5840e-01,  6.3437e-01,  1.1630e+00, -7.4901e-01],\n",
      "        [ 5.6499e-02, -1.1322e+00, -1.5358e+00, -1.3909e+00,  6.1586e-01,\n",
      "          4.1619e-01, -6.7470e-01, -5.1305e-01,  7.3172e-01,  2.3127e-01],\n",
      "        [-1.7113e+00, -1.2562e+00,  1.8536e+00, -1.9739e+00,  2.9262e-01,\n",
      "          5.6314e-01,  1.9863e+00,  1.3365e+00, -3.2727e-02,  3.0258e-01],\n",
      "        [ 1.4314e+00,  1.1611e-01, -1.1948e-01,  9.3354e-01,  2.0708e-01,\n",
      "          6.0305e-01,  1.3189e-02, -3.9272e-01, -1.8125e-01, -2.7300e-01],\n",
      "        [ 1.1472e+00, -1.1441e-01, -2.2268e-02,  1.2852e+00, -8.4258e-02,\n",
      "         -1.1514e-01,  1.0121e+00, -2.3848e-02,  2.0779e-01, -2.1561e+00],\n",
      "        [ 2.1974e-01, -1.1550e+00, -7.1227e-01, -1.7902e-01, -4.7229e-01,\n",
      "          1.3125e+00,  4.1439e-01, -5.4520e-01,  1.0421e+00, -7.0251e-01],\n",
      "        [ 7.9789e-01, -2.6787e-01,  1.6817e-01, -8.9241e-01,  6.2883e-02,\n",
      "         -2.0630e+00, -9.4598e-02, -9.1941e-01, -1.7468e-01,  5.2938e-01],\n",
      "        [ 3.3116e-01,  1.6225e+00,  4.7057e-01, -2.3960e-01,  3.4497e-01,\n",
      "         -1.5917e+00, -5.0700e-01, -1.4801e+00,  8.0271e-01, -4.9200e-01],\n",
      "        [ 3.2526e-01, -9.6784e-02, -9.2435e-01,  9.5481e-01, -7.7397e-01,\n",
      "          7.4211e-01, -3.0229e-01, -1.7003e-01, -5.7575e-01,  1.5753e+00],\n",
      "        [ 5.3906e-01, -5.1934e-01,  1.1476e-01, -1.2034e+00,  6.3790e-01,\n",
      "         -8.0914e-01,  8.5371e-01, -2.1232e-01,  1.1063e+00, -3.1832e-01],\n",
      "        [ 1.2628e-01,  1.5523e+00, -2.2664e+00,  1.3028e-02,  4.4296e-01,\n",
      "         -3.8006e-02,  4.0403e-01, -9.2467e-01,  1.0981e+00, -6.8162e-01],\n",
      "        [-2.7948e-01, -1.0958e+00, -4.3648e-02, -1.9923e-01, -7.4855e-01,\n",
      "         -1.1672e-01,  4.1667e-01,  2.8194e-01,  1.1458e+00,  8.3984e-01],\n",
      "        [-8.4433e-01,  5.5845e-01,  2.8564e-01, -6.8766e-01, -6.4204e-02,\n",
      "         -1.0017e+00,  2.6449e-01, -8.2306e-01,  2.7284e-01, -4.7676e-02],\n",
      "        [-3.9639e-02,  1.4738e+00,  1.1447e+00, -1.1958e-01,  7.8653e-01,\n",
      "          1.2327e-01,  3.2793e-01, -7.4015e-02,  4.6491e-01, -1.6413e+00],\n",
      "        [-5.7618e-02, -1.1489e-01, -2.9450e-01,  4.6317e-01, -3.7451e-01,\n",
      "         -1.6013e+00,  5.8185e-01, -1.4076e+00, -8.8651e-02,  3.3546e-01],\n",
      "        [ 4.8400e-01, -1.5580e+00,  4.7942e-01,  1.1383e+00,  5.4511e-01,\n",
      "         -1.2186e+00, -7.6661e-01,  3.5767e-01, -3.9446e-01,  4.9064e-01],\n",
      "        [-1.7835e-02, -4.7595e-01,  7.6824e-01, -8.7495e-01,  5.8421e-01,\n",
      "          1.0375e+00,  1.1357e+00, -1.5457e+00,  4.7162e-01,  5.4242e-01],\n",
      "        [-2.3379e-01,  6.0638e-01,  9.7252e-01, -1.2493e+00,  6.1671e-01,\n",
      "          9.2065e-01, -3.5210e-01, -1.2864e-02, -2.9795e-01, -4.5092e-01],\n",
      "        [-2.6012e-01,  1.0033e+00,  1.9903e-01, -2.8268e-01,  7.6713e-01,\n",
      "         -1.0720e-01,  1.7375e-01,  1.0775e+00, -1.3616e+00,  1.2720e+00],\n",
      "        [-1.5090e-01,  6.0970e-01, -1.2287e+00, -5.8650e-01,  3.6417e-01,\n",
      "         -4.3065e-01, -1.9301e+00,  1.2471e+00,  1.5418e+00, -1.4878e+00],\n",
      "        [ 5.2997e-01,  1.2741e+00,  1.3666e+00, -3.4749e-01, -4.6433e-01,\n",
      "          1.1469e-01,  6.2997e-01, -6.5662e-01, -1.2846e+00,  5.3744e-02],\n",
      "        [-2.3509e-01,  2.6003e-01, -8.3508e-01,  1.1933e+00, -4.4575e-01,\n",
      "          1.3598e+00,  8.1368e-02, -1.4251e+00,  7.3427e-01, -1.0818e+00],\n",
      "        [-4.4308e-01,  2.0604e+00,  2.1985e-01,  1.2245e-01, -6.9126e-01,\n",
      "         -5.6694e-01,  1.7373e-02,  8.6791e-01, -6.2569e-01, -1.5577e+00],\n",
      "        [-1.3102e+00, -7.2216e-01,  3.9818e-01,  1.5134e+00, -9.0721e-01,\n",
      "          1.0678e+00,  6.2579e-01,  1.2991e+00,  3.3698e-01,  3.1588e-02],\n",
      "        [ 1.5255e+00, -1.0528e+00, -3.7203e-02,  1.4320e+00,  2.1427e+00,\n",
      "          1.9184e-01, -9.7077e-01,  1.5597e-01, -6.1618e-01,  2.3033e-01],\n",
      "        [-3.6444e-01, -4.4470e-02, -1.4874e+00, -7.9496e-01, -1.0589e+00,\n",
      "         -8.5997e-02, -7.5003e-01,  6.9206e-01,  3.7469e-01,  3.0886e-01],\n",
      "        [ 2.0686e-01, -2.5066e-01, -1.0173e+00, -6.6508e-01, -8.2960e-01,\n",
      "         -5.5399e-01, -1.3119e-02, -8.6189e-03, -1.1525e+00,  3.6874e-01],\n",
      "        [ 1.3819e-02,  2.3869e-01,  1.3996e+00,  5.1110e-01,  7.9360e-01,\n",
      "          5.7367e-01, -1.2460e+00,  1.4377e+00, -4.7762e-01, -4.1760e-01],\n",
      "        [-1.2171e+00, -3.8566e-01,  5.5857e-01, -4.6541e-01,  1.2555e-01,\n",
      "         -3.0020e-01,  2.1104e+00, -1.1822e+00,  1.5388e-01, -1.6238e+00],\n",
      "        [ 3.9221e-01, -3.4336e-01, -9.8319e-01, -1.3762e-01, -2.4592e-01,\n",
      "         -1.0555e+00, -5.8777e-01,  4.6920e-01, -5.6889e-01,  1.7285e+00],\n",
      "        [-4.3594e-02,  6.6940e-02,  8.9857e-01,  6.3187e-02, -6.5965e-01,\n",
      "          1.3332e+00,  5.2150e-01,  1.2795e+00, -1.1136e+00,  1.1027e+00],\n",
      "        [ 8.8972e-01,  5.4532e-01, -1.7206e+00, -4.5448e-01,  6.3574e-01,\n",
      "         -3.3234e-01, -1.1354e+00, -6.0963e-01,  7.9432e-01, -2.7736e-01],\n",
      "        [-5.2761e-01,  2.0472e+00,  4.5792e-01, -1.7034e-01,  7.4129e-01,\n",
      "         -1.2596e+00, -3.2938e-01, -4.0872e-01,  7.9450e-01,  4.7815e-01],\n",
      "        [-9.6150e-01,  4.5556e-01, -1.7669e-01,  9.9730e-01, -1.5944e+00,\n",
      "         -6.5470e-01,  6.5211e-03, -5.6476e-01, -9.3453e-01,  2.9721e-01],\n",
      "        [-4.7579e-01,  1.2219e+00, -1.1130e+00,  9.9949e-02, -5.9431e-01,\n",
      "         -9.1815e-02, -1.7928e-01, -1.4091e+00,  6.7310e-01, -7.3904e-01],\n",
      "        [-5.0257e-01,  4.2603e-01,  4.6284e-01, -6.7179e-01, -9.8715e-02,\n",
      "         -2.4532e+00, -2.0654e-01, -4.6654e-01,  6.3831e-01, -1.6820e+00],\n",
      "        [ 1.1801e-01, -4.0695e-01,  5.7429e-01,  7.7065e-01,  1.8219e-01,\n",
      "          9.7279e-01,  7.4714e-01, -2.5804e-01, -1.9547e-01, -1.2706e-01],\n",
      "        [ 6.4809e-01, -7.9928e-01, -5.5403e-01,  1.3699e+00,  2.6844e-01,\n",
      "         -1.4409e+00,  8.6208e-01,  2.1653e-01,  1.8011e-01,  1.1011e+00],\n",
      "        [ 5.8388e-01,  2.9976e-02, -1.1578e+00, -1.2753e+00, -8.3010e-01,\n",
      "         -8.3246e-01, -1.4531e+00,  3.4877e-01, -5.8237e-01, -3.4786e-01],\n",
      "        [-3.2422e-01, -4.0512e-02,  9.6764e-01, -5.2679e-01, -2.6049e-01,\n",
      "         -1.0964e+00,  8.2588e-01, -9.6039e-01, -8.9618e-01,  3.0508e-01],\n",
      "        [ 9.8198e-01, -7.3291e-01, -1.9854e-01,  1.0261e-01,  3.8869e-01,\n",
      "          1.7284e-01, -3.9234e-01,  6.8136e-01,  1.9066e+00,  7.4162e-01],\n",
      "        [-1.2883e+00, -4.6737e-01, -9.0393e-01, -5.0369e-01,  2.9196e-01,\n",
      "          3.7666e-02,  1.0616e+00, -6.6185e-01,  7.3230e-01, -4.6247e-01],\n",
      "        [ 5.5917e-02,  1.0744e-01, -6.1280e-03, -1.3607e+00,  5.5116e-01,\n",
      "          4.5781e-01,  3.6112e-01,  1.7674e-01,  8.1571e-01,  8.7456e-01],\n",
      "        [-9.0277e-01,  1.4093e-01, -3.9119e-01,  1.2332e+00,  1.1150e+00,\n",
      "          1.5548e-01,  4.6045e-01,  2.8079e-01,  1.7727e+00,  1.8059e-01],\n",
      "        [ 5.2376e-01, -1.2164e+00,  1.0275e+00,  5.3823e-01, -7.9262e-01,\n",
      "         -9.9879e-02,  7.6877e-01, -2.2308e-01, -1.3896e+00, -5.1590e-01],\n",
      "        [-2.0535e-01,  2.2471e-01, -4.8163e-03, -9.7659e-01,  2.1671e-01,\n",
      "          5.9054e-03,  1.7450e-01,  4.1383e-01, -1.2220e+00, -8.8380e-01],\n",
      "        [ 4.0665e-01, -5.1433e-01,  2.7852e-01, -1.1186e+00,  4.0541e-01,\n",
      "         -6.7705e-01,  2.0924e+00, -8.3772e-01, -1.0523e+00,  1.4117e+00]])\n"
     ]
    }
   ],
   "source": [
    "#手动实现反向传播\n",
    "\n",
    "\n",
    "# Code in file tensor/two_layer_net_tensor.py\n",
    "import torch\n",
    " \n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU\n",
    " \n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    " \n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    " \n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device)\n",
    "w2 = torch.randn(H, D_out, device=device)\n",
    " \n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "  # Forward pass: compute predicted y\n",
    "  h = x.mm(w1)  #x与w1相乘\n",
    "  h_relu = h.clamp(min=0)  #设置h的input上下线，此处是下限为0\n",
    "  y_pred = h_relu.mm(w2)   #给model预测y赋值为激活函数h乘上一个w2参数\n",
    " \n",
    "  # Compute and print loss; loss is a scalar, and is stored in a PyTorch Tensor\n",
    "  # of shape (); we can get its value as a Python number with loss.item().\n",
    "  loss = (y_pred - y).pow(2).sum()\n",
    "  print(t, loss.item())\n",
    " \n",
    "  # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "  grad_y_pred = 2.0 * (y_pred - y)\n",
    "  grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "  grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "  grad_h = grad_h_relu.clone()\n",
    "  grad_h[h < 0] = 0\n",
    "  grad_w1 = x.t().mm(grad_h)\n",
    " \n",
    "  # Update weights using gradient descent\n",
    "  w1 -= learning_rate * grad_w1\n",
    "  w2 -= learning_rate * grad_w2\n",
    "\n",
    "print(w1,w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 31109852.0\n",
      "1 28812538.0\n",
      "2 27308410.0\n",
      "3 23786640.0\n",
      "4 18011938.0\n",
      "5 11969597.0\n",
      "6 7274300.0\n",
      "7 4358498.0\n",
      "8 2720972.5\n",
      "9 1834768.125\n",
      "10 1338406.375\n",
      "11 1041326.0\n",
      "12 848076.375\n",
      "13 711151.0\n",
      "14 607483.875\n",
      "15 525486.0\n",
      "16 458376.34375\n",
      "17 402303.21875\n",
      "18 354816.28125\n",
      "19 314211.6875\n",
      "20 279245.5625\n",
      "21 248934.296875\n",
      "22 222527.234375\n",
      "23 199440.953125\n",
      "24 179189.703125\n",
      "25 161361.765625\n",
      "26 145622.828125\n",
      "27 131691.46875\n",
      "28 119319.796875\n",
      "29 108304.8671875\n",
      "30 98481.546875\n",
      "31 89696.703125\n",
      "32 81819.1171875\n",
      "33 74747.1875\n",
      "34 68383.9765625\n",
      "35 62654.96875\n",
      "36 57489.7890625\n",
      "37 52825.546875\n",
      "38 48599.28125\n",
      "39 44764.14453125\n",
      "40 41277.92578125\n",
      "41 38104.8515625\n",
      "42 35215.51953125\n",
      "43 32580.65625\n",
      "44 30174.0703125\n",
      "45 27971.841796875\n",
      "46 25955.595703125\n",
      "47 24106.76171875\n",
      "48 22409.47265625\n",
      "49 20849.88671875\n",
      "50 19414.10546875\n",
      "51 18091.173828125\n",
      "52 16871.537109375\n",
      "53 15746.3203125\n",
      "54 14707.5400390625\n",
      "55 13747.0380859375\n",
      "56 12857.6796875\n",
      "57 12033.802734375\n",
      "58 11270.64453125\n",
      "59 10563.0703125\n",
      "60 9906.39453125\n",
      "61 9296.681640625\n",
      "62 8729.302734375\n",
      "63 8201.416015625\n",
      "64 7709.9765625\n",
      "65 7252.048828125\n",
      "66 6826.458984375\n",
      "67 6429.04736328125\n",
      "68 6057.990234375\n",
      "69 5711.08447265625\n",
      "70 5386.6416015625\n",
      "71 5083.052734375\n",
      "72 4798.76171875\n",
      "73 4532.57568359375\n",
      "74 4282.876953125\n",
      "75 4048.6484375\n",
      "76 3828.752685546875\n",
      "77 3622.361328125\n",
      "78 3428.392578125\n",
      "79 3246.251708984375\n",
      "80 3074.960205078125\n",
      "81 2913.80615234375\n",
      "82 2762.1416015625\n",
      "83 2619.30810546875\n",
      "84 2484.8759765625\n",
      "85 2358.148681640625\n",
      "86 2238.67138671875\n",
      "87 2125.89990234375\n",
      "88 2019.4442138671875\n",
      "89 1918.9144287109375\n",
      "90 1823.947509765625\n",
      "91 1734.1341552734375\n",
      "92 1649.24609375\n",
      "93 1568.901611328125\n",
      "94 1492.8665771484375\n",
      "95 1420.8963623046875\n",
      "96 1352.7396240234375\n",
      "97 1288.1539306640625\n",
      "98 1226.935546875\n",
      "99 1168.91455078125\n",
      "100 1113.9154052734375\n",
      "101 1061.7156982421875\n",
      "102 1012.2245483398438\n",
      "103 965.2122802734375\n",
      "104 920.5806274414062\n",
      "105 878.1755981445312\n",
      "106 837.9037475585938\n",
      "107 799.6336059570312\n",
      "108 763.2619018554688\n",
      "109 728.6961059570312\n",
      "110 695.842529296875\n",
      "111 664.59521484375\n",
      "112 634.8583984375\n",
      "113 606.5746459960938\n",
      "114 579.61572265625\n",
      "115 553.945068359375\n",
      "116 529.5035400390625\n",
      "117 506.2149658203125\n",
      "118 484.02117919921875\n",
      "119 462.87213134765625\n",
      "120 442.7052307128906\n",
      "121 423.4792175292969\n",
      "122 405.14630126953125\n",
      "123 387.6569519042969\n",
      "124 370.97296142578125\n",
      "125 355.055419921875\n",
      "126 339.8551025390625\n",
      "127 325.345458984375\n",
      "128 311.4952087402344\n",
      "129 298.2686767578125\n",
      "130 285.6363525390625\n",
      "131 273.56964111328125\n",
      "132 262.03387451171875\n",
      "133 251.01541137695312\n",
      "134 240.48765563964844\n",
      "135 230.42410278320312\n",
      "136 220.8051300048828\n",
      "137 211.60800170898438\n",
      "138 202.8080596923828\n",
      "139 194.39752197265625\n",
      "140 186.3497772216797\n",
      "141 178.65206909179688\n",
      "142 171.28733825683594\n",
      "143 164.23899841308594\n",
      "144 157.49368286132812\n",
      "145 151.03659057617188\n",
      "146 144.85516357421875\n",
      "147 138.939208984375\n",
      "148 133.27626037597656\n",
      "149 127.85370635986328\n",
      "150 122.65943145751953\n",
      "151 117.68380737304688\n",
      "152 112.91726684570312\n",
      "153 108.35184478759766\n",
      "154 103.97998809814453\n",
      "155 99.7898941040039\n",
      "156 95.77671813964844\n",
      "157 91.92839050292969\n",
      "158 88.23998260498047\n",
      "159 84.7045669555664\n",
      "160 81.31582641601562\n",
      "161 78.06781768798828\n",
      "162 74.95443725585938\n",
      "163 71.96715545654297\n",
      "164 69.10572814941406\n",
      "165 66.35860443115234\n",
      "166 63.726505279541016\n",
      "167 61.19882583618164\n",
      "168 58.777069091796875\n",
      "169 56.45113754272461\n",
      "170 54.22184371948242\n",
      "171 52.08161926269531\n",
      "172 50.030189514160156\n",
      "173 48.06145477294922\n",
      "174 46.17238235473633\n",
      "175 44.3580322265625\n",
      "176 42.61814498901367\n",
      "177 40.94648742675781\n",
      "178 39.34291076660156\n",
      "179 37.803524017333984\n",
      "180 36.325439453125\n",
      "181 34.90716552734375\n",
      "182 33.54527282714844\n",
      "183 32.23809814453125\n",
      "184 30.98223114013672\n",
      "185 29.77701187133789\n",
      "186 28.619136810302734\n",
      "187 27.508270263671875\n",
      "188 26.440847396850586\n",
      "189 25.41514778137207\n",
      "190 24.430316925048828\n",
      "191 23.484149932861328\n",
      "192 22.576210021972656\n",
      "193 21.70380973815918\n",
      "194 20.865224838256836\n",
      "195 20.059368133544922\n",
      "196 19.285924911499023\n",
      "197 18.542484283447266\n",
      "198 17.828235626220703\n",
      "199 17.142024993896484\n",
      "200 16.48302459716797\n",
      "201 15.849162101745605\n",
      "202 15.240645408630371\n",
      "203 14.655750274658203\n",
      "204 14.09330940246582\n",
      "205 13.553199768066406\n",
      "206 13.033014297485352\n",
      "207 12.534439086914062\n",
      "208 12.05434799194336\n",
      "209 11.593161582946777\n",
      "210 11.150113105773926\n",
      "211 10.724485397338867\n",
      "212 10.31471061706543\n",
      "213 9.92104434967041\n",
      "214 9.542632102966309\n",
      "215 9.17873764038086\n",
      "216 8.828862190246582\n",
      "217 8.492871284484863\n",
      "218 8.169466018676758\n",
      "219 7.858826160430908\n",
      "220 7.559474468231201\n",
      "221 7.272303581237793\n",
      "222 6.99573278427124\n",
      "223 6.7302656173706055\n",
      "224 6.474637985229492\n",
      "225 6.229008197784424\n",
      "226 5.992617607116699\n",
      "227 5.76542329788208\n",
      "228 5.546885013580322\n",
      "229 5.336816787719727\n",
      "230 5.1348066329956055\n",
      "231 4.940324306488037\n",
      "232 4.7535810470581055\n",
      "233 4.573774814605713\n",
      "234 4.4007792472839355\n",
      "235 4.234709739685059\n",
      "236 4.074653148651123\n",
      "237 3.920891284942627\n",
      "238 3.7729363441467285\n",
      "239 3.630446672439575\n",
      "240 3.493488311767578\n",
      "241 3.3617124557495117\n",
      "242 3.2348992824554443\n",
      "243 3.1129794120788574\n",
      "244 2.9957003593444824\n",
      "245 2.8828766345977783\n",
      "246 2.774176836013794\n",
      "247 2.6699347496032715\n",
      "248 2.569371461868286\n",
      "249 2.472907543182373\n",
      "250 2.3800148963928223\n",
      "251 2.2905359268188477\n",
      "252 2.2042455673217773\n",
      "253 2.1215083599090576\n",
      "254 2.0418074131011963\n",
      "255 1.9651998281478882\n",
      "256 1.8913471698760986\n",
      "257 1.8204395771026611\n",
      "258 1.7521185874938965\n",
      "259 1.6863371133804321\n",
      "260 1.6231235265731812\n",
      "261 1.5621938705444336\n",
      "262 1.5037436485290527\n",
      "263 1.447371244430542\n",
      "264 1.3931678533554077\n",
      "265 1.340976357460022\n",
      "266 1.2907359600067139\n",
      "267 1.2423373460769653\n",
      "268 1.1958997249603271\n",
      "269 1.1511282920837402\n",
      "270 1.1080780029296875\n",
      "271 1.0666865110397339\n",
      "272 1.0268182754516602\n",
      "273 0.9884302616119385\n",
      "274 0.9515023827552795\n",
      "275 0.915848433971405\n",
      "276 0.8816171884536743\n",
      "277 0.8487883806228638\n",
      "278 0.8170480132102966\n",
      "279 0.7865071892738342\n",
      "280 0.7572424411773682\n",
      "281 0.7289981842041016\n",
      "282 0.7017545700073242\n",
      "283 0.6755406856536865\n",
      "284 0.6503538489341736\n",
      "285 0.6260252594947815\n",
      "286 0.6027910709381104\n",
      "287 0.5803394317626953\n",
      "288 0.5586565732955933\n",
      "289 0.5378643274307251\n",
      "290 0.5177978277206421\n",
      "291 0.49853140115737915\n",
      "292 0.47989699244499207\n",
      "293 0.46200302243232727\n",
      "294 0.44477975368499756\n",
      "295 0.4281883239746094\n",
      "296 0.41231828927993774\n",
      "297 0.3969917893409729\n",
      "298 0.38225388526916504\n",
      "299 0.367979496717453\n",
      "300 0.35433053970336914\n",
      "301 0.3411487936973572\n",
      "302 0.32843875885009766\n",
      "303 0.3162495791912079\n",
      "304 0.30447909235954285\n",
      "305 0.29322147369384766\n",
      "306 0.28230801224708557\n",
      "307 0.27183544635772705\n",
      "308 0.2616846561431885\n",
      "309 0.25195008516311646\n",
      "310 0.24262653291225433\n",
      "311 0.2336021065711975\n",
      "312 0.22491812705993652\n",
      "313 0.21655435860157013\n",
      "314 0.20857718586921692\n",
      "315 0.20081864297389984\n",
      "316 0.1933593600988388\n",
      "317 0.18614400923252106\n",
      "318 0.1792575865983963\n",
      "319 0.17259417474269867\n",
      "320 0.16618286073207855\n",
      "321 0.16002650558948517\n",
      "322 0.1540895402431488\n",
      "323 0.14835727214813232\n",
      "324 0.1428508758544922\n",
      "325 0.1375706046819687\n",
      "326 0.13246577978134155\n",
      "327 0.12756778299808502\n",
      "328 0.12282807379961014\n",
      "329 0.1182723343372345\n",
      "330 0.11395227164030075\n",
      "331 0.1097210943698883\n",
      "332 0.10566525906324387\n",
      "333 0.10173202306032181\n",
      "334 0.09798021614551544\n",
      "335 0.09434521198272705\n",
      "336 0.09085527062416077\n",
      "337 0.08748188614845276\n",
      "338 0.08424928784370422\n",
      "339 0.08114700019359589\n",
      "340 0.07814181596040726\n",
      "341 0.07526792585849762\n",
      "342 0.0724702998995781\n",
      "343 0.0697941705584526\n",
      "344 0.06721111387014389\n",
      "345 0.06476498395204544\n",
      "346 0.06234924867749214\n",
      "347 0.060071494430303574\n",
      "348 0.05785558372735977\n",
      "349 0.05571294203400612\n",
      "350 0.05364878475666046\n",
      "351 0.051663968712091446\n",
      "352 0.049756329506635666\n",
      "353 0.04792701080441475\n",
      "354 0.04616112262010574\n",
      "355 0.04447564482688904\n",
      "356 0.04281911253929138\n",
      "357 0.0412587895989418\n",
      "358 0.03973755985498428\n",
      "359 0.038270533084869385\n",
      "360 0.03685189411044121\n",
      "361 0.035492077469825745\n",
      "362 0.03419102728366852\n",
      "363 0.03293222934007645\n",
      "364 0.031736280769109726\n",
      "365 0.030578268691897392\n",
      "366 0.029454844072461128\n",
      "367 0.028364872559905052\n",
      "368 0.02733432501554489\n",
      "369 0.02633499540388584\n",
      "370 0.025373447686433792\n",
      "371 0.024449899792671204\n",
      "372 0.023549014702439308\n",
      "373 0.022673286497592926\n",
      "374 0.021858861669898033\n",
      "375 0.021054264158010483\n",
      "376 0.02029837854206562\n",
      "377 0.019564660266041756\n",
      "378 0.01885121688246727\n",
      "379 0.0181602593511343\n",
      "380 0.017506977543234825\n",
      "381 0.01686953753232956\n",
      "382 0.01626240648329258\n",
      "383 0.015669317916035652\n",
      "384 0.015107480809092522\n",
      "385 0.014559129253029823\n",
      "386 0.014028271660208702\n",
      "387 0.013521709479391575\n",
      "388 0.013029873371124268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389 0.012560858391225338\n",
      "390 0.012107543647289276\n",
      "391 0.011672843247652054\n",
      "392 0.011257714591920376\n",
      "393 0.010859287343919277\n",
      "394 0.01046798750758171\n",
      "395 0.010086710564792156\n",
      "396 0.009730379097163677\n",
      "397 0.009382086805999279\n",
      "398 0.009052202105522156\n",
      "399 0.008726879023015499\n",
      "400 0.008419369347393513\n",
      "401 0.008121725171804428\n",
      "402 0.00784169789403677\n",
      "403 0.0075671738013625145\n",
      "404 0.0073023405857384205\n",
      "405 0.007038268260657787\n",
      "406 0.006795134861022234\n",
      "407 0.006557194050401449\n",
      "408 0.006331526208668947\n",
      "409 0.006111170630902052\n",
      "410 0.005903318058699369\n",
      "411 0.005698333960026503\n",
      "412 0.005499598570168018\n",
      "413 0.005313810892403126\n",
      "414 0.005127099342644215\n",
      "415 0.0049514081329107285\n",
      "416 0.004779623821377754\n",
      "417 0.004618410486727953\n",
      "418 0.004463473334908485\n",
      "419 0.004311115015298128\n",
      "420 0.004161748103797436\n",
      "421 0.004017828963696957\n",
      "422 0.003886522725224495\n",
      "423 0.003758043982088566\n",
      "424 0.0036321745719760656\n",
      "425 0.0035112760961055756\n",
      "426 0.0033951853401958942\n",
      "427 0.003282967722043395\n",
      "428 0.003176239551976323\n",
      "429 0.003068453399464488\n",
      "430 0.002967648673802614\n",
      "431 0.0028713156934827566\n",
      "432 0.0027791974134743214\n",
      "433 0.002691103843972087\n",
      "434 0.002601779066026211\n",
      "435 0.0025204650592058897\n",
      "436 0.0024404486175626516\n",
      "437 0.0023634526878595352\n",
      "438 0.002289172960445285\n",
      "439 0.0022179021034389734\n",
      "440 0.0021464244928210974\n",
      "441 0.0020814461167901754\n",
      "442 0.0020166179165244102\n",
      "443 0.0019514622399583459\n",
      "444 0.0018927992787212133\n",
      "445 0.0018363443668931723\n",
      "446 0.001781849074177444\n",
      "447 0.001726158312521875\n",
      "448 0.001670842757448554\n",
      "449 0.0016206756699830294\n",
      "450 0.0015741847455501556\n",
      "451 0.0015304014086723328\n",
      "452 0.001483045401982963\n",
      "453 0.0014410926960408688\n",
      "454 0.0013986376579850912\n",
      "455 0.0013602364342659712\n",
      "456 0.001320729381404817\n",
      "457 0.0012834735680371523\n",
      "458 0.001245004590600729\n",
      "459 0.001211034832522273\n",
      "460 0.001176988473162055\n",
      "461 0.0011444847332313657\n",
      "462 0.001112254336476326\n",
      "463 0.0010804702760651708\n",
      "464 0.0010516493348404765\n",
      "465 0.0010246284073218703\n",
      "466 0.0009968059603124857\n",
      "467 0.0009689924772828817\n",
      "468 0.0009436341933906078\n",
      "469 0.0009177009342238307\n",
      "470 0.0008943950524553657\n",
      "471 0.0008697419543750584\n",
      "472 0.0008476345101371408\n",
      "473 0.0008246438228525221\n",
      "474 0.000802292546723038\n",
      "475 0.0007821968756616116\n",
      "476 0.000761230883654207\n",
      "477 0.0007414016872644424\n",
      "478 0.0007236049859784544\n",
      "479 0.0007053883746266365\n",
      "480 0.0006868920172564685\n",
      "481 0.000670198758598417\n",
      "482 0.0006523583433590829\n",
      "483 0.0006370642222464085\n",
      "484 0.0006210865103639662\n",
      "485 0.0006053954130038619\n",
      "486 0.0005898298695683479\n",
      "487 0.0005771583528257906\n",
      "488 0.0005630390369333327\n",
      "489 0.0005492768250405788\n",
      "490 0.0005362300435081124\n",
      "491 0.000524260220117867\n",
      "492 0.0005122955772094429\n",
      "493 0.0004990767920389771\n",
      "494 0.00048741334467194974\n",
      "495 0.00047684114542789757\n",
      "496 0.0004653586947824806\n",
      "497 0.0004539178335107863\n",
      "498 0.0004444411606527865\n",
      "499 0.00043386503239162266\n"
     ]
    }
   ],
   "source": [
    "#autograd 自动反向传播\n",
    "\n",
    "# Code in file autograd/two_layer_net_autograd.py\n",
    "import torch\n",
    " \n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU\n",
    " \n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    " \n",
    "# Create random Tensors to hold input and outputs\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    " \n",
    "# Create random Tensors for weights; setting requires_grad=True means that we\n",
    "# want to compute gradients for these Tensors during the backward pass.\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    " \n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "  # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n",
    "  # w2 have requires_grad=True, operations involving these Tensors will cause\n",
    "  # PyTorch to build a computational graph, allowing automatic computation of\n",
    "  # gradients. Since we are no longer implementing the backward pass by hand we\n",
    "  # don't need to keep references to intermediate values.\n",
    "  y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "  \n",
    "  # Compute and print loss. Loss is a Tensor of shape (), and loss.item()\n",
    "  # is a Python number giving its value.\n",
    "  loss = (y_pred - y).pow(2).sum()\n",
    "  print(t, loss.item())\n",
    " \n",
    "  # Use autograd to compute the backward pass. This call will compute the\n",
    "  # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "  # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
    "  # of the loss with respect to w1 and w2 respectively.\n",
    "  loss.backward()\n",
    " \n",
    "  # Update weights using gradient descent. For this step we just want to mutate\n",
    "  # the values of w1 and w2 in-place; we don't want to build up a computational\n",
    "  # graph for the update steps, so we use the torch.no_grad() context manager\n",
    "  # to prevent PyTorch from building a computational graph for the updates\n",
    "  with torch.no_grad():\n",
    "    w1 -= learning_rate * w1.grad\n",
    "    w2 -= learning_rate * w2.grad\n",
    " \n",
    "    # Manually zero the gradients after running the backward pass\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 48698772.0\n",
      "1 47006088.0\n",
      "2 41726524.0\n",
      "3 28617540.0\n",
      "4 14930096.0\n",
      "5 6872810.5\n",
      "6 3460589.0\n",
      "7 2119709.75\n",
      "8 1517763.5\n",
      "9 1182610.125\n",
      "10 958880.875\n",
      "11 793490.625\n",
      "12 664617.5625\n",
      "13 561360.6875\n",
      "14 477524.90625\n",
      "15 408757.625\n",
      "16 351852.21875\n",
      "17 304433.78125\n",
      "18 264612.875\n",
      "19 230964.875\n",
      "20 202383.6875\n",
      "21 177960.171875\n",
      "22 156992.953125\n",
      "23 138937.4375\n",
      "24 123292.234375\n",
      "25 109661.640625\n",
      "26 97776.9453125\n",
      "27 87376.6875\n",
      "28 78259.3046875\n",
      "29 70237.640625\n",
      "30 63156.0078125\n",
      "31 56895.859375\n",
      "32 51341.32421875\n",
      "33 46402.29296875\n",
      "34 42004.10546875\n",
      "35 38084.65625\n",
      "36 34581.56640625\n",
      "37 31441.37890625\n",
      "38 28623.4765625\n",
      "39 26090.630859375\n",
      "40 23809.748046875\n",
      "41 21753.87890625\n",
      "42 19897.265625\n",
      "43 18219.23046875\n",
      "44 16700.041015625\n",
      "45 15322.5546875\n",
      "46 14072.755859375\n",
      "47 12937.005859375\n",
      "48 11903.62109375\n",
      "49 10962.3818359375\n",
      "50 10104.24609375\n",
      "51 9321.177734375\n",
      "52 8605.55859375\n",
      "53 7951.119140625\n",
      "54 7351.8837890625\n",
      "55 6802.44091796875\n",
      "56 6298.55810546875\n",
      "57 5835.80078125\n",
      "58 5410.72509765625\n",
      "59 5020.57568359375\n",
      "60 4661.64404296875\n",
      "61 4330.92041015625\n",
      "62 4026.10546875\n",
      "63 3744.893310546875\n",
      "64 3485.28125\n",
      "65 3245.3359375\n",
      "66 3023.640625\n",
      "67 2818.6953125\n",
      "68 2628.9599609375\n",
      "69 2453.12451171875\n",
      "70 2290.0927734375\n",
      "71 2138.870361328125\n",
      "72 1998.5911865234375\n",
      "73 1868.21435546875\n",
      "74 1747.0667724609375\n",
      "75 1634.4383544921875\n",
      "76 1529.68505859375\n",
      "77 1432.1639404296875\n",
      "78 1341.356201171875\n",
      "79 1256.7506103515625\n",
      "80 1177.88671875\n",
      "81 1104.3365478515625\n",
      "82 1035.7105712890625\n",
      "83 971.674072265625\n",
      "84 911.8958740234375\n",
      "85 856.0255737304688\n",
      "86 803.8076171875\n",
      "87 754.9866333007812\n",
      "88 709.4189453125\n",
      "89 666.811279296875\n",
      "90 626.9222412109375\n",
      "91 589.5668334960938\n",
      "92 554.5779418945312\n",
      "93 521.7969970703125\n",
      "94 491.0693664550781\n",
      "95 462.2624816894531\n",
      "96 435.2486572265625\n",
      "97 409.9033203125\n",
      "98 386.1187438964844\n",
      "99 363.79168701171875\n",
      "100 342.8285827636719\n",
      "101 323.1322326660156\n",
      "102 304.6296691894531\n",
      "103 287.2434997558594\n",
      "104 270.8883972167969\n",
      "105 255.51548767089844\n",
      "106 241.057373046875\n",
      "107 227.45956420898438\n",
      "108 214.6603546142578\n",
      "109 202.6115264892578\n",
      "110 191.2711944580078\n",
      "111 180.5892333984375\n",
      "112 170.53431701660156\n",
      "113 161.0597381591797\n",
      "114 152.13629150390625\n",
      "115 143.72669982910156\n",
      "116 135.8022003173828\n",
      "117 128.32798767089844\n",
      "118 121.28121948242188\n",
      "119 114.63524627685547\n",
      "120 108.36719512939453\n",
      "121 102.4526596069336\n",
      "122 96.8761978149414\n",
      "123 91.6109390258789\n",
      "124 86.64351654052734\n",
      "125 81.95271301269531\n",
      "126 77.52581024169922\n",
      "127 73.34565734863281\n",
      "128 69.39698028564453\n",
      "129 65.66788482666016\n",
      "130 62.14567947387695\n",
      "131 58.81654357910156\n",
      "132 55.672969818115234\n",
      "133 52.70065689086914\n",
      "134 49.89073944091797\n",
      "135 47.2370491027832\n",
      "136 44.728790283203125\n",
      "137 42.3560905456543\n",
      "138 40.11178207397461\n",
      "139 37.99006652832031\n",
      "140 35.9833984375\n",
      "141 34.08555603027344\n",
      "142 32.29095458984375\n",
      "143 30.59218406677246\n",
      "144 28.98490333557129\n",
      "145 27.464387893676758\n",
      "146 26.025413513183594\n",
      "147 24.664081573486328\n",
      "148 23.375028610229492\n",
      "149 22.155120849609375\n",
      "150 20.999263763427734\n",
      "151 19.90629005432129\n",
      "152 18.870899200439453\n",
      "153 17.890201568603516\n",
      "154 16.961923599243164\n",
      "155 16.083158493041992\n",
      "156 15.250714302062988\n",
      "157 14.461774826049805\n",
      "158 13.714658737182617\n",
      "159 13.006528854370117\n",
      "160 12.336380004882812\n",
      "161 11.701295852661133\n",
      "162 11.09848403930664\n",
      "163 10.528291702270508\n",
      "164 9.987550735473633\n",
      "165 9.475388526916504\n",
      "166 8.989288330078125\n",
      "167 8.529292106628418\n",
      "168 8.092309951782227\n",
      "169 7.67888879776001\n",
      "170 7.286766529083252\n",
      "171 6.914755821228027\n",
      "172 6.561784267425537\n",
      "173 6.2279815673828125\n",
      "174 5.910528659820557\n",
      "175 5.610034942626953\n",
      "176 5.324927806854248\n",
      "177 5.054659843444824\n",
      "178 4.797943115234375\n",
      "179 4.554887771606445\n",
      "180 4.3241472244262695\n",
      "181 4.105213165283203\n",
      "182 3.8973076343536377\n",
      "183 3.700477123260498\n",
      "184 3.513411045074463\n",
      "185 3.3359265327453613\n",
      "186 3.167703866958618\n",
      "187 3.007972002029419\n",
      "188 2.856658458709717\n",
      "189 2.7128283977508545\n",
      "190 2.5762176513671875\n",
      "191 2.446676254272461\n",
      "192 2.3238134384155273\n",
      "193 2.2069199085235596\n",
      "194 2.096061944961548\n",
      "195 1.991163969039917\n",
      "196 1.8914769887924194\n",
      "197 1.7967486381530762\n",
      "198 1.7067937850952148\n",
      "199 1.6213597059249878\n",
      "200 1.5403448343276978\n",
      "201 1.463456153869629\n",
      "202 1.3903210163116455\n",
      "203 1.3208577632904053\n",
      "204 1.2550517320632935\n",
      "205 1.192461609840393\n",
      "206 1.1330410242080688\n",
      "207 1.0766358375549316\n",
      "208 1.0230227708816528\n",
      "209 0.9721815586090088\n",
      "210 0.9238883256912231\n",
      "211 0.8779363036155701\n",
      "212 0.8342861533164978\n",
      "213 0.7929397821426392\n",
      "214 0.7536283135414124\n",
      "215 0.7163024544715881\n",
      "216 0.6807252764701843\n",
      "217 0.6470262408256531\n",
      "218 0.6149799823760986\n",
      "219 0.5845025181770325\n",
      "220 0.5556325316429138\n",
      "221 0.5281767249107361\n",
      "222 0.5020298957824707\n",
      "223 0.4772545397281647\n",
      "224 0.4537469148635864\n",
      "225 0.43133434653282166\n",
      "226 0.4100818634033203\n",
      "227 0.38983723521232605\n",
      "228 0.37058672308921814\n",
      "229 0.3523833155632019\n",
      "230 0.3350445032119751\n",
      "231 0.31854450702667236\n",
      "232 0.3028993308544159\n",
      "233 0.2879692614078522\n",
      "234 0.2738732099533081\n",
      "235 0.26038599014282227\n",
      "236 0.2476108819246292\n",
      "237 0.23546019196510315\n",
      "238 0.22388920187950134\n",
      "239 0.21293899416923523\n",
      "240 0.2024766504764557\n",
      "241 0.19254368543624878\n",
      "242 0.1830904632806778\n",
      "243 0.17412999272346497\n",
      "244 0.16565130650997162\n",
      "245 0.15752695500850677\n",
      "246 0.14981108903884888\n",
      "247 0.1424889862537384\n",
      "248 0.13557803630828857\n",
      "249 0.12892624735832214\n",
      "250 0.1226419061422348\n",
      "251 0.11666910350322723\n",
      "252 0.11098204553127289\n",
      "253 0.10554441064596176\n",
      "254 0.10040654987096786\n",
      "255 0.09552363306283951\n",
      "256 0.09084714949131012\n",
      "257 0.08642172068357468\n",
      "258 0.08223192393779755\n",
      "259 0.07823128998279572\n",
      "260 0.07441239058971405\n",
      "261 0.07081472873687744\n",
      "262 0.0673818588256836\n",
      "263 0.06411159783601761\n",
      "264 0.06098232790827751\n",
      "265 0.05805094167590141\n",
      "266 0.05521540716290474\n",
      "267 0.05255427584052086\n",
      "268 0.05001142621040344\n",
      "269 0.047589752823114395\n",
      "270 0.045273978263139725\n",
      "271 0.04308459162712097\n",
      "272 0.04099750518798828\n",
      "273 0.03900916501879692\n",
      "274 0.037131477147340775\n",
      "275 0.03533845394849777\n",
      "276 0.033625487238168716\n",
      "277 0.03200596570968628\n",
      "278 0.030465610325336456\n",
      "279 0.02900979481637478\n",
      "280 0.027607277035713196\n",
      "281 0.02627960592508316\n",
      "282 0.02500641718506813\n",
      "283 0.023812884464859962\n",
      "284 0.022673621773719788\n",
      "285 0.02158239111304283\n",
      "286 0.020553650334477425\n",
      "287 0.019575752317905426\n",
      "288 0.018647171556949615\n",
      "289 0.01774267479777336\n",
      "290 0.016901038587093353\n",
      "291 0.016099151223897934\n",
      "292 0.015331525355577469\n",
      "293 0.014601127244532108\n",
      "294 0.013915687799453735\n",
      "295 0.013250274583697319\n",
      "296 0.012619647197425365\n",
      "297 0.012033401057124138\n",
      "298 0.011463223956525326\n",
      "299 0.010917898267507553\n",
      "300 0.010401623323559761\n",
      "301 0.00991737935692072\n",
      "302 0.009456411004066467\n",
      "303 0.009009278379380703\n",
      "304 0.008590786717832088\n",
      "305 0.008189398795366287\n",
      "306 0.00781020475551486\n",
      "307 0.007443483453243971\n",
      "308 0.007094293832778931\n",
      "309 0.006772216409444809\n",
      "310 0.006457579787820578\n",
      "311 0.006160689517855644\n",
      "312 0.005883452948182821\n",
      "313 0.005614738445729017\n",
      "314 0.0053581432439386845\n",
      "315 0.005108967423439026\n",
      "316 0.004885339178144932\n",
      "317 0.0046598948538303375\n",
      "318 0.0044534821063280106\n",
      "319 0.004252721555531025\n",
      "320 0.004061565268784761\n",
      "321 0.003877804847434163\n",
      "322 0.003705242183059454\n",
      "323 0.0035447939299046993\n",
      "324 0.0033854146022349596\n",
      "325 0.0032368686515837908\n",
      "326 0.0030934743117541075\n",
      "327 0.002958145923912525\n",
      "328 0.0028309973422437906\n",
      "329 0.0027110991068184376\n",
      "330 0.0025949394330382347\n",
      "331 0.0024840186815708876\n",
      "332 0.0023776772432029247\n",
      "333 0.0022774003446102142\n",
      "334 0.002180267358198762\n",
      "335 0.0020888675935566425\n",
      "336 0.002003374742344022\n",
      "337 0.001921745017170906\n",
      "338 0.0018413019133731723\n",
      "339 0.0017660934245213866\n",
      "340 0.0016942941583693027\n",
      "341 0.0016265494050458074\n",
      "342 0.00155975844245404\n",
      "343 0.0014989017508924007\n",
      "344 0.0014409812865778804\n",
      "345 0.0013828109949827194\n",
      "346 0.001326830592006445\n",
      "347 0.001276784110814333\n",
      "348 0.0012268268037587404\n",
      "349 0.0011791023425757885\n",
      "350 0.001135370577685535\n",
      "351 0.0010921709472313523\n",
      "352 0.0010505005484446883\n",
      "353 0.001012309454381466\n",
      "354 0.0009746694704517722\n",
      "355 0.0009389925398863852\n",
      "356 0.0009043648024089634\n",
      "357 0.0008705555810593069\n",
      "358 0.0008380776271224022\n",
      "359 0.0008086016750894487\n",
      "360 0.0007794762495905161\n",
      "361 0.0007528176065534353\n",
      "362 0.0007273117080330849\n",
      "363 0.0007012887508608401\n",
      "364 0.0006761074182577431\n",
      "365 0.0006537818117067218\n",
      "366 0.0006325594149529934\n",
      "367 0.0006112910923548043\n",
      "368 0.0005921850097365677\n",
      "369 0.0005711601115763187\n",
      "370 0.0005527567700482905\n",
      "371 0.0005348735139705241\n",
      "372 0.0005169013165868819\n",
      "373 0.0005009073065593839\n",
      "374 0.00048517962568439543\n",
      "375 0.00046961935004219413\n",
      "376 0.0004552256432361901\n",
      "377 0.00043961979099549353\n",
      "378 0.0004264346498530358\n",
      "379 0.0004142172692809254\n",
      "380 0.00040202634409070015\n",
      "381 0.0003894651890732348\n",
      "382 0.00037781946593895555\n",
      "383 0.00036635639844462276\n",
      "384 0.00035497720818966627\n",
      "385 0.00034509378019720316\n",
      "386 0.00033396913204342127\n",
      "387 0.0003244838153477758\n",
      "388 0.00031565819517709315\n",
      "389 0.0003066762874368578\n",
      "390 0.0002980423450935632\n",
      "391 0.00029013503808528185\n",
      "392 0.00028193191974423826\n",
      "393 0.00027383986162021756\n",
      "394 0.00026553976931609213\n",
      "395 0.00025902449851855636\n",
      "396 0.0002522857394069433\n",
      "397 0.0002457086811773479\n",
      "398 0.00023909207084216177\n",
      "399 0.0002334607852390036\n",
      "400 0.00022741020075045526\n",
      "401 0.00022124027600511909\n",
      "402 0.00021455963724292815\n",
      "403 0.00020940080867148936\n",
      "404 0.00020444746769499034\n",
      "405 0.00019952343427576125\n",
      "406 0.00019502034410834312\n",
      "407 0.0001902674266602844\n",
      "408 0.00018579578318167478\n",
      "409 0.00018113991245627403\n",
      "410 0.00017651598318479955\n",
      "411 0.0001727237249724567\n",
      "412 0.00016826170030981302\n",
      "413 0.00016431933909188956\n",
      "414 0.00016091522411443293\n",
      "415 0.00015734006592538208\n",
      "416 0.00015429535415023565\n",
      "417 0.00015049429202917963\n",
      "418 0.00014787903637625277\n",
      "419 0.00014368905976880342\n",
      "420 0.00014107518654782325\n",
      "421 0.00013796631537843496\n",
      "422 0.0001350237726001069\n",
      "423 0.00013216563093010336\n",
      "424 0.0001294550602324307\n",
      "425 0.00012708774011116475\n",
      "426 0.00012445342144928873\n",
      "427 0.00012199805496493354\n",
      "428 0.0001193145799334161\n",
      "429 0.00011681826435960829\n",
      "430 0.00011462377005955204\n",
      "431 0.00011220214946661144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432 0.00010988646681653336\n",
      "433 0.00010802468023030087\n",
      "434 0.00010561008093645796\n",
      "435 0.00010360265150666237\n",
      "436 0.00010160137026105076\n",
      "437 9.970449900720268e-05\n",
      "438 9.780786058399826e-05\n",
      "439 9.641629003454e-05\n",
      "440 9.463880996918306e-05\n",
      "441 9.286097338190302e-05\n",
      "442 9.113542182603851e-05\n",
      "443 8.942994463723153e-05\n",
      "444 8.75299156177789e-05\n",
      "445 8.58327402966097e-05\n",
      "446 8.454686758341268e-05\n",
      "447 8.296868327306584e-05\n",
      "448 8.15375242382288e-05\n",
      "449 8.002867252798751e-05\n",
      "450 7.880920020397753e-05\n",
      "451 7.745487528154626e-05\n",
      "452 7.618948438903317e-05\n",
      "453 7.469373667845502e-05\n",
      "454 7.389457459794357e-05\n",
      "455 7.286064646905288e-05\n",
      "456 7.136417116271332e-05\n",
      "457 7.008256216067821e-05\n",
      "458 6.900566950207576e-05\n",
      "459 6.797299283789471e-05\n",
      "460 6.70891095069237e-05\n",
      "461 6.602618668694049e-05\n",
      "462 6.505173951154575e-05\n",
      "463 6.381747516570613e-05\n",
      "464 6.271243910305202e-05\n",
      "465 6.189177656779066e-05\n",
      "466 6.082378968130797e-05\n",
      "467 5.989955388940871e-05\n",
      "468 5.863378100912087e-05\n",
      "469 5.79707084398251e-05\n",
      "470 5.728582254960202e-05\n",
      "471 5.6546316045569256e-05\n",
      "472 5.565606988966465e-05\n",
      "473 5.478670209413394e-05\n",
      "474 5.402928218245506e-05\n",
      "475 5.3239160479279235e-05\n",
      "476 5.2488532674033195e-05\n",
      "477 5.194466939428821e-05\n",
      "478 5.114070154377259e-05\n",
      "479 5.044000135967508e-05\n",
      "480 4.979494769941084e-05\n",
      "481 4.9171430873684585e-05\n",
      "482 4.855637962464243e-05\n",
      "483 4.798425652552396e-05\n",
      "484 4.743048702948727e-05\n",
      "485 4.6636294428026304e-05\n",
      "486 4.5965723984409124e-05\n",
      "487 4.526355769485235e-05\n",
      "488 4.4666961912298575e-05\n",
      "489 4.4092284952057526e-05\n",
      "490 4.370567694422789e-05\n",
      "491 4.30749605584424e-05\n",
      "492 4.241839997121133e-05\n",
      "493 4.1864819650072604e-05\n",
      "494 4.141737736063078e-05\n",
      "495 4.09768326790072e-05\n",
      "496 4.064965833094902e-05\n",
      "497 4.0074690332403407e-05\n",
      "498 3.9561022276757285e-05\n",
      "499 3.895820918842219e-05\n"
     ]
    }
   ],
   "source": [
    "#    在PyTorch中我们可以通过定义torch.autograd.Function子类\n",
    "#和实现forward和backward函数来定义我们自己的autograd操作。\n",
    "#然后我们可以通过创建实例来使用新的autograd操作，并像函数一样调用，\n",
    "#传播Tensor。\n",
    "\n",
    "# Code in file autograd/two_layer_net_custom_function.py\n",
    "import torch\n",
    " \n",
    "class MyReLU(torch.autograd.Function):\n",
    "  \"\"\"\n",
    "  We can implement our own custom autograd Functions by subclassing\n",
    "  torch.autograd.Function and implementing the forward and backward passes\n",
    "  which operate on Tensors.\n",
    "  \"\"\"\n",
    "  @staticmethod\n",
    "  def forward(ctx, x):\n",
    "    \"\"\"\n",
    "    In the forward pass we receive a context object and a Tensor containing the\n",
    "    input; we must return a Tensor containing the output, and we can use the\n",
    "    context object to cache objects for use in the backward pass.\n",
    "    \"\"\"\n",
    "    ctx.save_for_backward(x)\n",
    "    return x.clamp(min=0)\n",
    " \n",
    "  def backward(ctx, grad_output):\n",
    "    \"\"\"\n",
    "    In the backward pass we receive the context object and a Tensor containing\n",
    "    the gradient of the loss with respect to the output produced during the\n",
    "    forward pass. We can retrieve cached data from the context object, and must\n",
    "    compute and return the gradient of the loss with respect to the input to the\n",
    "    forward function.\n",
    "    \"\"\"\n",
    "    x, = ctx.saved_tensors\n",
    "    grad_x = grad_output.clone()\n",
    "    grad_x[x < 0] = 0\n",
    "    return grad_x\n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "# Create random Tensors to hold input and output\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "# Create random Tensors for weights.\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "  # Forward pass: compute predicted y using operations on Tensors; we call our\n",
    "  # custom ReLU implementation using the MyReLU.apply function\n",
    "  y_pred = MyReLU.apply(x.mm(w1)).mm(w2)\n",
    " \n",
    "  # Compute and print loss\n",
    "  loss = (y_pred - y).pow(2).sum()\n",
    "  print(t, loss.item())\n",
    "  # Use autograd to compute the backward pass.\n",
    "  loss.backward()\n",
    "  with torch.no_grad():\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * w1.grad\n",
    "    w2 -= learning_rate * w2.grad\n",
    "    # Manually zero the gradients after running the backward pass\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 733.460205078125\n",
      "1 675.2667846679688\n",
      "2 624.9657592773438\n",
      "3 581.22998046875\n",
      "4 542.4168701171875\n",
      "5 507.5355224609375\n",
      "6 476.0512390136719\n",
      "7 447.3106689453125\n",
      "8 420.8769836425781\n",
      "9 396.2803039550781\n",
      "10 373.37091064453125\n",
      "11 351.8489990234375\n",
      "12 331.7290954589844\n",
      "13 312.8040466308594\n",
      "14 294.7820129394531\n",
      "15 277.69915771484375\n",
      "16 261.4081115722656\n",
      "17 245.91004943847656\n",
      "18 231.2219696044922\n",
      "19 217.28248596191406\n",
      "20 204.03433227539062\n",
      "21 191.5157012939453\n",
      "22 179.6929473876953\n",
      "23 168.5435791015625\n",
      "24 158.01904296875\n",
      "25 148.1019287109375\n",
      "26 138.7822265625\n",
      "27 130.0263671875\n",
      "28 121.8121566772461\n",
      "29 114.09151458740234\n",
      "30 106.84748840332031\n",
      "31 100.05162811279297\n",
      "32 93.70541381835938\n",
      "33 87.77469635009766\n",
      "34 82.24079895019531\n",
      "35 77.05770874023438\n",
      "36 72.19026184082031\n",
      "37 67.63948059082031\n",
      "38 63.38191604614258\n",
      "39 59.371551513671875\n",
      "40 55.623329162597656\n",
      "41 52.12847137451172\n",
      "42 48.869815826416016\n",
      "43 45.83354568481445\n",
      "44 42.99934005737305\n",
      "45 40.34906005859375\n",
      "46 37.87310028076172\n",
      "47 35.55834197998047\n",
      "48 33.3836784362793\n",
      "49 31.35211181640625\n",
      "50 29.4559268951416\n",
      "51 27.68238639831543\n",
      "52 26.023103713989258\n",
      "53 24.471397399902344\n",
      "54 23.018766403198242\n",
      "55 21.659914016723633\n",
      "56 20.389822006225586\n",
      "57 19.20115852355957\n",
      "58 18.09264373779297\n",
      "59 17.05038070678711\n",
      "60 16.074260711669922\n",
      "61 15.15919303894043\n",
      "62 14.302329063415527\n",
      "63 13.498106956481934\n",
      "64 12.743230819702148\n",
      "65 12.034109115600586\n",
      "66 11.368074417114258\n",
      "67 10.742594718933105\n",
      "68 10.154241561889648\n",
      "69 9.601161003112793\n",
      "70 9.081769943237305\n",
      "71 8.592841148376465\n",
      "72 8.133910179138184\n",
      "73 7.702105522155762\n",
      "74 7.2956223487854\n",
      "75 6.912955284118652\n",
      "76 6.551839828491211\n",
      "77 6.211112976074219\n",
      "78 5.89021635055542\n",
      "79 5.588204383850098\n",
      "80 5.30310583114624\n",
      "81 5.034178733825684\n",
      "82 4.780516147613525\n",
      "83 4.5407304763793945\n",
      "84 4.314305782318115\n",
      "85 4.100106239318848\n",
      "86 3.897709608078003\n",
      "87 3.70605731010437\n",
      "88 3.5249104499816895\n",
      "89 3.3535163402557373\n",
      "90 3.19110369682312\n",
      "91 3.037076473236084\n",
      "92 2.8915038108825684\n",
      "93 2.7534713745117188\n",
      "94 2.622565269470215\n",
      "95 2.498699903488159\n",
      "96 2.381258487701416\n",
      "97 2.269742250442505\n",
      "98 2.1638903617858887\n",
      "99 2.0634517669677734\n",
      "100 1.9681159257888794\n",
      "101 1.8776311874389648\n",
      "102 1.7915915250778198\n",
      "103 1.7099642753601074\n",
      "104 1.6322365999221802\n",
      "105 1.5583502054214478\n",
      "106 1.4880505800247192\n",
      "107 1.421223521232605\n",
      "108 1.3576698303222656\n",
      "109 1.2972118854522705\n",
      "110 1.2396868467330933\n",
      "111 1.1848942041397095\n",
      "112 1.13270103931427\n",
      "113 1.083052635192871\n",
      "114 1.0357345342636108\n",
      "115 0.9906841516494751\n",
      "116 0.9477613568305969\n",
      "117 0.906822919845581\n",
      "118 0.8678425550460815\n",
      "119 0.830685555934906\n",
      "120 0.7952582836151123\n",
      "121 0.7614569664001465\n",
      "122 0.7292554378509521\n",
      "123 0.6985573172569275\n",
      "124 0.6692542433738708\n",
      "125 0.6412892937660217\n",
      "126 0.6145833730697632\n",
      "127 0.5890923738479614\n",
      "128 0.5647610425949097\n",
      "129 0.5415254235267639\n",
      "130 0.5193142890930176\n",
      "131 0.49811315536499023\n",
      "132 0.47783368825912476\n",
      "133 0.45842328667640686\n",
      "134 0.4398679733276367\n",
      "135 0.4221334755420685\n",
      "136 0.40518918633461\n",
      "137 0.3889877498149872\n",
      "138 0.373492568731308\n",
      "139 0.35867297649383545\n",
      "140 0.34450024366378784\n",
      "141 0.33089232444763184\n",
      "142 0.31786924600601196\n",
      "143 0.305393248796463\n",
      "144 0.2934491038322449\n",
      "145 0.28200989961624146\n",
      "146 0.27104923129081726\n",
      "147 0.26055631041526794\n",
      "148 0.25050824880599976\n",
      "149 0.24088479578495026\n",
      "150 0.23165631294250488\n",
      "151 0.22282159328460693\n",
      "152 0.21434339880943298\n",
      "153 0.20621825754642487\n",
      "154 0.1984272450208664\n",
      "155 0.19095243513584137\n",
      "156 0.18378210067749023\n",
      "157 0.1769028902053833\n",
      "158 0.1702994406223297\n",
      "159 0.16396589577198029\n",
      "160 0.15787911415100098\n",
      "161 0.15203863382339478\n",
      "162 0.14643511176109314\n",
      "163 0.14104872941970825\n",
      "164 0.13588042557239532\n",
      "165 0.13091105222702026\n",
      "166 0.12613703310489655\n",
      "167 0.12155786156654358\n",
      "168 0.11716340482234955\n",
      "169 0.11293433606624603\n",
      "170 0.10887208580970764\n",
      "171 0.10496830940246582\n",
      "172 0.10121539235115051\n",
      "173 0.09760314971208572\n",
      "174 0.09413277357816696\n",
      "175 0.09079460799694061\n",
      "176 0.08758506178855896\n",
      "177 0.08449488878250122\n",
      "178 0.08152343332767487\n",
      "179 0.07866567373275757\n",
      "180 0.07591459155082703\n",
      "181 0.07326782494783401\n",
      "182 0.07071907818317413\n",
      "183 0.06826499104499817\n",
      "184 0.06590273231267929\n",
      "185 0.06362876296043396\n",
      "186 0.06143825501203537\n",
      "187 0.05932973325252533\n",
      "188 0.05729806050658226\n",
      "189 0.055341336876153946\n",
      "190 0.05345583334565163\n",
      "191 0.05164836347103119\n",
      "192 0.04990755021572113\n",
      "193 0.04823117330670357\n",
      "194 0.046614229679107666\n",
      "195 0.045056022703647614\n",
      "196 0.043553676456213\n",
      "197 0.042106591165065765\n",
      "198 0.04071122780442238\n",
      "199 0.03936551511287689\n",
      "200 0.038067713379859924\n",
      "201 0.03681493178009987\n",
      "202 0.03560706973075867\n",
      "203 0.03444211557507515\n",
      "204 0.033318258821964264\n",
      "205 0.032233402132987976\n",
      "206 0.03118758648633957\n",
      "207 0.030181758105754852\n",
      "208 0.029211245477199554\n",
      "209 0.028274400159716606\n",
      "210 0.027369827032089233\n",
      "211 0.026495713740587234\n",
      "212 0.025652121752500534\n",
      "213 0.024837376549839973\n",
      "214 0.024050340056419373\n",
      "215 0.023290015757083893\n",
      "216 0.022555585950613022\n",
      "217 0.021845942363142967\n",
      "218 0.021160444244742393\n",
      "219 0.020497974008321762\n",
      "220 0.01985744759440422\n",
      "221 0.019238170236349106\n",
      "222 0.018640708178281784\n",
      "223 0.018076566979289055\n",
      "224 0.01753140427172184\n",
      "225 0.01700443960726261\n",
      "226 0.016494637355208397\n",
      "227 0.016001686453819275\n",
      "228 0.015525110997259617\n",
      "229 0.015064536593854427\n",
      "230 0.014618657529354095\n",
      "231 0.014187173917889595\n",
      "232 0.013769966550171375\n",
      "233 0.013366143219172955\n",
      "234 0.012975113466382027\n",
      "235 0.01259682234376669\n",
      "236 0.012230563908815384\n",
      "237 0.011875970289111137\n",
      "238 0.011532527394592762\n",
      "239 0.011200269684195518\n",
      "240 0.01087834220379591\n",
      "241 0.010566464625298977\n",
      "242 0.010264413431286812\n",
      "243 0.00997163262218237\n",
      "244 0.00968790240585804\n",
      "245 0.009413032792508602\n",
      "246 0.009146650321781635\n",
      "247 0.008888371288776398\n",
      "248 0.008638176135718822\n",
      "249 0.008395764976739883\n",
      "250 0.008160498924553394\n",
      "251 0.007932446897029877\n",
      "252 0.007711417507380247\n",
      "253 0.007496995851397514\n",
      "254 0.007288970984518528\n",
      "255 0.007087210193276405\n",
      "256 0.006891492288559675\n",
      "257 0.006701682228595018\n",
      "258 0.00651759747415781\n",
      "259 0.006338873412460089\n",
      "260 0.006165467668324709\n",
      "261 0.005997227970510721\n",
      "262 0.005833870731294155\n",
      "263 0.005675304681062698\n",
      "264 0.005521392449736595\n",
      "265 0.005371996201574802\n",
      "266 0.0052269222214818\n",
      "267 0.0050862692296504974\n",
      "268 0.004949458874762058\n",
      "269 0.0048166122287511826\n",
      "270 0.004687638022005558\n",
      "271 0.0045623574405908585\n",
      "272 0.00444067595526576\n",
      "273 0.004322529304772615\n",
      "274 0.004207677207887173\n",
      "275 0.004096123389899731\n",
      "276 0.003987712319940329\n",
      "277 0.0038824069779366255\n",
      "278 0.0037800089921802282\n",
      "279 0.003680555149912834\n",
      "280 0.0035838454496115446\n",
      "281 0.0034899034071713686\n",
      "282 0.0033985497429966927\n",
      "283 0.003309716237708926\n",
      "284 0.0032233907841145992\n",
      "285 0.003139444161206484\n",
      "286 0.003057834692299366\n",
      "287 0.0029784629587084055\n",
      "288 0.002901331288740039\n",
      "289 0.0028262482956051826\n",
      "290 0.002753273583948612\n",
      "291 0.002682362450286746\n",
      "292 0.0026132939383387566\n",
      "293 0.0025461306795477867\n",
      "294 0.002480786759406328\n",
      "295 0.0024172132834792137\n",
      "296 0.0023553723003715277\n",
      "297 0.002295226790010929\n",
      "298 0.002236642176285386\n",
      "299 0.0021796878427267075\n",
      "300 0.0021242285147309303\n",
      "301 0.0020702839829027653\n",
      "302 0.002017837017774582\n",
      "303 0.0019667153246700764\n",
      "304 0.0019169645383954048\n",
      "305 0.0018685406539589167\n",
      "306 0.001821415382437408\n",
      "307 0.001775540760718286\n",
      "308 0.0017308529932051897\n",
      "309 0.0016873712884262204\n",
      "310 0.0016450295224785805\n",
      "311 0.0016038041794672608\n",
      "312 0.001563653931953013\n",
      "313 0.0015245431568473577\n",
      "314 0.001486469409428537\n",
      "315 0.0014493947383016348\n",
      "316 0.0014132884098216891\n",
      "317 0.0013781184097751975\n",
      "318 0.0013438465539366007\n",
      "319 0.0013104863464832306\n",
      "320 0.0012779850512742996\n",
      "321 0.0012463224120438099\n",
      "322 0.0012154784053564072\n",
      "323 0.0011854367330670357\n",
      "324 0.0011561783030629158\n",
      "325 0.0011276766890659928\n",
      "326 0.0010998781071975827\n",
      "327 0.0010728066554293036\n",
      "328 0.0010464302031323314\n",
      "329 0.0010207202285528183\n",
      "330 0.000995665555819869\n",
      "331 0.0009712344035506248\n",
      "332 0.0009474472608417273\n",
      "333 0.0009242566302418709\n",
      "334 0.0009016634430736303\n",
      "335 0.0008796500042080879\n",
      "336 0.000858205312397331\n",
      "337 0.0008372653392143548\n",
      "338 0.0008168743806891143\n",
      "339 0.0007969849393703043\n",
      "340 0.0007776010315865278\n",
      "341 0.0007587035652250051\n",
      "342 0.000740285380743444\n",
      "343 0.0007223234279081225\n",
      "344 0.0007048192201182246\n",
      "345 0.0006877461564727128\n",
      "346 0.000671110232360661\n",
      "347 0.0006548771634697914\n",
      "348 0.0006390503840520978\n",
      "349 0.000623615924268961\n",
      "350 0.0006085763452574611\n",
      "351 0.0005939066759310663\n",
      "352 0.0005795942852273583\n",
      "353 0.0005656473222188652\n",
      "354 0.0005520355189219117\n",
      "355 0.0005387715063989162\n",
      "356 0.0005258289747871459\n",
      "357 0.0005132053629495203\n",
      "358 0.0005008839070796967\n",
      "359 0.0004888836992904544\n",
      "360 0.0004771672247443348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 0.0004657409735955298\n",
      "362 0.00045460023102350533\n",
      "363 0.0004437332972884178\n",
      "364 0.00043312559137120843\n",
      "365 0.00042279099579900503\n",
      "366 0.0004126919084228575\n",
      "367 0.00040285199065692723\n",
      "368 0.00039325153920799494\n",
      "369 0.00038390106055885553\n",
      "370 0.0003747536102309823\n",
      "371 0.00036583386827260256\n",
      "372 0.0003571310662664473\n",
      "373 0.00034864709596149623\n",
      "374 0.0003403625451028347\n",
      "375 0.00033227764652110636\n",
      "376 0.0003243916726205498\n",
      "377 0.0003166954847984016\n",
      "378 0.0003091850667260587\n",
      "379 0.00030186300864443183\n",
      "380 0.00029471423476934433\n",
      "381 0.0002877400547731668\n",
      "382 0.000280928798019886\n",
      "383 0.00027428477187640965\n",
      "384 0.0002678038727026433\n",
      "385 0.00026147637981921434\n",
      "386 0.0002553029917180538\n",
      "387 0.0002492734638508409\n",
      "388 0.00024339626543223858\n",
      "389 0.00023765477817505598\n",
      "390 0.0002320536586921662\n",
      "391 0.00022658455418422818\n",
      "392 0.0002212454710388556\n",
      "393 0.0002160400035791099\n",
      "394 0.0002109564666170627\n",
      "395 0.00020599467097781599\n",
      "396 0.00020115316146984696\n",
      "397 0.00019642282859422266\n",
      "398 0.00019180693197995424\n",
      "399 0.0001873022993095219\n",
      "400 0.00018290527805220336\n",
      "401 0.0001786189095582813\n",
      "402 0.00017442846728954464\n",
      "403 0.00017033777839969844\n",
      "404 0.00016634508210700005\n",
      "405 0.00016244265134446323\n",
      "406 0.00015863982844166458\n",
      "407 0.0001549209118820727\n",
      "408 0.00015129483654163778\n",
      "409 0.00014775616000406444\n",
      "410 0.00014429655857384205\n",
      "411 0.00014092389028519392\n",
      "412 0.00013762772141490132\n",
      "413 0.00013440934708341956\n",
      "414 0.00013126849080435932\n",
      "415 0.00012820004485547543\n",
      "416 0.00012520792370196432\n",
      "417 0.00012228367268107831\n",
      "418 0.00011942879064008594\n",
      "419 0.00011663822078844532\n",
      "420 0.00011392089072614908\n",
      "421 0.00011126434401376173\n",
      "422 0.00010866681259358302\n",
      "423 0.0001061370421666652\n",
      "424 0.00010366104106651619\n",
      "425 0.00010124489199370146\n",
      "426 9.88868996500969e-05\n",
      "427 9.658181807026267e-05\n",
      "428 9.433762897970155e-05\n",
      "429 9.21393366297707e-05\n",
      "430 8.999494457384571e-05\n",
      "431 8.79017316037789e-05\n",
      "432 8.585808973293751e-05\n",
      "433 8.386379340663552e-05\n",
      "434 8.191318192984909e-05\n",
      "435 8.000855450518429e-05\n",
      "436 7.814873970346525e-05\n",
      "437 7.633336645085365e-05\n",
      "438 7.455814920831472e-05\n",
      "439 7.282843580469489e-05\n",
      "440 7.113548053894192e-05\n",
      "441 6.948319787625223e-05\n",
      "442 6.787112215533853e-05\n",
      "443 6.629696144955233e-05\n",
      "444 6.475780537584797e-05\n",
      "445 6.325454160105437e-05\n",
      "446 6.178853800520301e-05\n",
      "447 6.0356374888215214e-05\n",
      "448 5.8954086853191257e-05\n",
      "449 5.759002669947222e-05\n",
      "450 5.6252618378493935e-05\n",
      "451 5.4949967307038605e-05\n",
      "452 5.367760968510993e-05\n",
      "453 5.243259874987416e-05\n",
      "454 5.121875074109994e-05\n",
      "455 5.003288242733106e-05\n",
      "456 4.887352406512946e-05\n",
      "457 4.7742265451233834e-05\n",
      "458 4.6635916078230366e-05\n",
      "459 4.555727355182171e-05\n",
      "460 4.4504133256850764e-05\n",
      "461 4.347404319560155e-05\n",
      "462 4.246663593221456e-05\n",
      "463 4.1485945985186845e-05\n",
      "464 4.052650183439255e-05\n",
      "465 3.958921297453344e-05\n",
      "466 3.86728897865396e-05\n",
      "467 3.7779176636831835e-05\n",
      "468 3.690690209623426e-05\n",
      "469 3.6053621442988515e-05\n",
      "470 3.521976395859383e-05\n",
      "471 3.440492582740262e-05\n",
      "472 3.361054041306488e-05\n",
      "473 3.283535625087097e-05\n",
      "474 3.2075269700726494e-05\n",
      "475 3.1335512176156044e-05\n",
      "476 3.061121969949454e-05\n",
      "477 2.9905302653787658e-05\n",
      "478 2.9214512323960662e-05\n",
      "479 2.8540551284095272e-05\n",
      "480 2.788145502563566e-05\n",
      "481 2.7237285394221544e-05\n",
      "482 2.661068174347747e-05\n",
      "483 2.5994104362325743e-05\n",
      "484 2.539400702517014e-05\n",
      "485 2.4809509341139346e-05\n",
      "486 2.4236902390839532e-05\n",
      "487 2.367759407206904e-05\n",
      "488 2.3132677597459406e-05\n",
      "489 2.2599097064812668e-05\n",
      "490 2.2076588720665313e-05\n",
      "491 2.1569354430539533e-05\n",
      "492 2.107041837007273e-05\n",
      "493 2.0585408492479473e-05\n",
      "494 2.011023389059119e-05\n",
      "495 1.9647934095701203e-05\n",
      "496 1.9194983906345442e-05\n",
      "497 1.8751870811684057e-05\n",
      "498 1.8320992239750922e-05\n",
      "499 1.7898551959660836e-05\n"
     ]
    }
   ],
   "source": [
    "#    在PyTorch中，nn包具有同样的作用。 nn包定义了一组模块，\n",
    "#    它们大致相当于神经网络层。模块接收输入Tensor并计算输出Tensor，\n",
    "#    但也可以保持内部状态，例如包含可学习参数的Tensor。\n",
    "#    nn包还定义了一组在训练神经网络时常用的有用的损失函数。\n",
    "\n",
    "\n",
    "# Code in file nn/two_layer_net_nn.py\n",
    "import torch\n",
    "\n",
    " \n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU\n",
    " \n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    " \n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    " \n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "# After constructing the model we use the .to() method to move it to the\n",
    "# desired device.\n",
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H, D_out),\n",
    "        ).to(device)\n",
    " \n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    " \n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "  # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "  # override the __call__ operator so you can call them like functions. When\n",
    "  # doing so you pass a Tensor of input data to the Module and it produces\n",
    "  # a Tensor of output data.\n",
    "  y_pred = model(x)\n",
    " \n",
    "  # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "  # values of y, and the loss function returns a Tensor containing the loss.\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  print(t, loss.item())\n",
    "\n",
    "  \n",
    "  # Zero the gradients before running the backward pass.\n",
    "  model.zero_grad()\n",
    " \n",
    "  # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "  # parameters of the model. Internally, the parameters of each Module are stored\n",
    "  # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "  # all learnable parameters in the model.\n",
    "  loss.backward()\n",
    " \n",
    "  # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "  # we can access its data and gradients like we did before.\n",
    "  with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "      param.data -= learning_rate * param.grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 654.140625\n",
      "1 637.6131591796875\n",
      "2 621.5366821289062\n",
      "3 605.8927001953125\n",
      "4 590.781494140625\n",
      "5 576.076171875\n",
      "6 561.779296875\n",
      "7 547.9662475585938\n",
      "8 534.6185302734375\n",
      "9 521.6929931640625\n",
      "10 509.1822204589844\n",
      "11 497.0024719238281\n",
      "12 485.204833984375\n",
      "13 473.72125244140625\n",
      "14 462.6139221191406\n",
      "15 451.83782958984375\n",
      "16 441.3051452636719\n",
      "17 431.09210205078125\n",
      "18 421.1272888183594\n",
      "19 411.454833984375\n",
      "20 402.05853271484375\n",
      "21 392.8824768066406\n",
      "22 383.9479064941406\n",
      "23 375.2609558105469\n",
      "24 366.7999267578125\n",
      "25 358.5826416015625\n",
      "26 350.5694580078125\n",
      "27 342.7445983886719\n",
      "28 335.10382080078125\n",
      "29 327.6232604980469\n",
      "30 320.33929443359375\n",
      "31 313.2378234863281\n",
      "32 306.2790832519531\n",
      "33 299.4718933105469\n",
      "34 292.82830810546875\n",
      "35 286.3410339355469\n",
      "36 279.992919921875\n",
      "37 273.786865234375\n",
      "38 267.6823425292969\n",
      "39 261.6813049316406\n",
      "40 255.81317138671875\n",
      "41 250.0522003173828\n",
      "42 244.39830017089844\n",
      "43 238.8625030517578\n",
      "44 233.4343719482422\n",
      "45 228.09872436523438\n",
      "46 222.87620544433594\n",
      "47 217.74191284179688\n",
      "48 212.7021942138672\n",
      "49 207.76718139648438\n",
      "50 202.92564392089844\n",
      "51 198.19529724121094\n",
      "52 193.5594482421875\n",
      "53 189.0062255859375\n",
      "54 184.54522705078125\n",
      "55 180.1793212890625\n",
      "56 175.8860626220703\n",
      "57 171.67160034179688\n",
      "58 167.53573608398438\n",
      "59 163.48153686523438\n",
      "60 159.50978088378906\n",
      "61 155.61279296875\n",
      "62 151.7693328857422\n",
      "63 147.99234008789062\n",
      "64 144.28822326660156\n",
      "65 140.65475463867188\n",
      "66 137.10166931152344\n",
      "67 133.61737060546875\n",
      "68 130.1988983154297\n",
      "69 126.85134887695312\n",
      "70 123.56981658935547\n",
      "71 120.34909057617188\n",
      "72 117.19859313964844\n",
      "73 114.11776733398438\n",
      "74 111.091552734375\n",
      "75 108.12645721435547\n",
      "76 105.22222137451172\n",
      "77 102.37053680419922\n",
      "78 99.57538604736328\n",
      "79 96.84808349609375\n",
      "80 94.17730712890625\n",
      "81 91.55892944335938\n",
      "82 88.99811553955078\n",
      "83 86.48638916015625\n",
      "84 84.02875518798828\n",
      "85 81.62716674804688\n",
      "86 79.27861785888672\n",
      "87 76.98529815673828\n",
      "88 74.74689483642578\n",
      "89 72.55755615234375\n",
      "90 70.41422271728516\n",
      "91 68.3213882446289\n",
      "92 66.2763900756836\n",
      "93 64.2808837890625\n",
      "94 62.33224868774414\n",
      "95 60.430511474609375\n",
      "96 58.57550048828125\n",
      "97 56.76264953613281\n",
      "98 54.9912223815918\n",
      "99 53.262451171875\n",
      "100 51.5760498046875\n",
      "101 49.93144607543945\n",
      "102 48.32887649536133\n",
      "103 46.76734924316406\n",
      "104 45.24599075317383\n",
      "105 43.76594924926758\n",
      "106 42.328311920166016\n",
      "107 40.93135452270508\n",
      "108 39.57255554199219\n",
      "109 38.246944427490234\n",
      "110 36.95808792114258\n",
      "111 35.706451416015625\n",
      "112 34.49174118041992\n",
      "113 33.31156921386719\n",
      "114 32.16527557373047\n",
      "115 31.05221939086914\n",
      "116 29.971790313720703\n",
      "117 28.925792694091797\n",
      "118 27.908802032470703\n",
      "119 26.922761917114258\n",
      "120 25.967147827148438\n",
      "121 25.04059410095215\n",
      "122 24.142654418945312\n",
      "123 23.27365493774414\n",
      "124 22.433517456054688\n",
      "125 21.62034034729004\n",
      "126 20.831417083740234\n",
      "127 20.068397521972656\n",
      "128 19.33080291748047\n",
      "129 18.618152618408203\n",
      "130 17.928546905517578\n",
      "131 17.261926651000977\n",
      "132 16.617677688598633\n",
      "133 15.994028091430664\n",
      "134 15.392477989196777\n",
      "135 14.810494422912598\n",
      "136 14.248229026794434\n",
      "137 13.705301284790039\n",
      "138 13.181044578552246\n",
      "139 12.674932479858398\n",
      "140 12.18723201751709\n",
      "141 11.715803146362305\n",
      "142 11.261472702026367\n",
      "143 10.823267936706543\n",
      "144 10.400921821594238\n",
      "145 9.99356460571289\n",
      "146 9.600923538208008\n",
      "147 9.222651481628418\n",
      "148 8.858070373535156\n",
      "149 8.50642204284668\n",
      "150 8.16755199432373\n",
      "151 7.841240406036377\n",
      "152 7.5270466804504395\n",
      "153 7.224117279052734\n",
      "154 6.932528495788574\n",
      "155 6.651724815368652\n",
      "156 6.381153106689453\n",
      "157 6.121417045593262\n",
      "158 5.871208190917969\n",
      "159 5.630825996398926\n",
      "160 5.399660110473633\n",
      "161 5.177313804626465\n",
      "162 4.963393688201904\n",
      "163 4.757513046264648\n",
      "164 4.559678077697754\n",
      "165 4.369583606719971\n",
      "166 4.18703031539917\n",
      "167 4.011663436889648\n",
      "168 3.8431508541107178\n",
      "169 3.6811904907226562\n",
      "170 3.525634765625\n",
      "171 3.376152992248535\n",
      "172 3.232679605484009\n",
      "173 3.094761848449707\n",
      "174 2.962275981903076\n",
      "175 2.83522367477417\n",
      "176 2.7134408950805664\n",
      "177 2.5963542461395264\n",
      "178 2.4839420318603516\n",
      "179 2.3762495517730713\n",
      "180 2.2729485034942627\n",
      "181 2.1737844944000244\n",
      "182 2.078629732131958\n",
      "183 1.9875426292419434\n",
      "184 1.9001785516738892\n",
      "185 1.8164947032928467\n",
      "186 1.736193299293518\n",
      "187 1.6592988967895508\n",
      "188 1.5855368375778198\n",
      "189 1.5148472785949707\n",
      "190 1.4471207857131958\n",
      "191 1.3822746276855469\n",
      "192 1.3200547695159912\n",
      "193 1.2604656219482422\n",
      "194 1.203535556793213\n",
      "195 1.149101972579956\n",
      "196 1.0969607830047607\n",
      "197 1.0470821857452393\n",
      "198 0.9993407130241394\n",
      "199 0.9536615610122681\n",
      "200 0.9099041223526001\n",
      "201 0.8680658340454102\n",
      "202 0.8280261158943176\n",
      "203 0.789749264717102\n",
      "204 0.7531107068061829\n",
      "205 0.718044638633728\n",
      "206 0.6845338940620422\n",
      "207 0.6524806618690491\n",
      "208 0.6218395233154297\n",
      "209 0.5925456881523132\n",
      "210 0.5645465850830078\n",
      "211 0.5377998352050781\n",
      "212 0.5122507810592651\n",
      "213 0.4878164529800415\n",
      "214 0.46448445320129395\n",
      "215 0.4422149956226349\n",
      "216 0.4209529161453247\n",
      "217 0.4006378650665283\n",
      "218 0.38124537467956543\n",
      "219 0.36271578073501587\n",
      "220 0.345054566860199\n",
      "221 0.32819756865501404\n",
      "222 0.31212520599365234\n",
      "223 0.2967878580093384\n",
      "224 0.28216180205345154\n",
      "225 0.26820671558380127\n",
      "226 0.2549118399620056\n",
      "227 0.24222442507743835\n",
      "228 0.23013240098953247\n",
      "229 0.2186126559972763\n",
      "230 0.2076798975467682\n",
      "231 0.19730491936206818\n",
      "232 0.18741531670093536\n",
      "233 0.17800043523311615\n",
      "234 0.1690363883972168\n",
      "235 0.16050951182842255\n",
      "236 0.1523865908384323\n",
      "237 0.14464974403381348\n",
      "238 0.1372910737991333\n",
      "239 0.13029129803180695\n",
      "240 0.12363413721323013\n",
      "241 0.11729835718870163\n",
      "242 0.1112743690609932\n",
      "243 0.10554635524749756\n",
      "244 0.10009894520044327\n",
      "245 0.09491907060146332\n",
      "246 0.0899968072772026\n",
      "247 0.08531804382801056\n",
      "248 0.08087064325809479\n",
      "249 0.07664816826581955\n",
      "250 0.0726364254951477\n",
      "251 0.06882880628108978\n",
      "252 0.06521499902009964\n",
      "253 0.06178348511457443\n",
      "254 0.05852438509464264\n",
      "255 0.05543133616447449\n",
      "256 0.052494198083877563\n",
      "257 0.04970724135637283\n",
      "258 0.047063663601875305\n",
      "259 0.044553644955158234\n",
      "260 0.04217284545302391\n",
      "261 0.03991355746984482\n",
      "262 0.03777190297842026\n",
      "263 0.03574011102318764\n",
      "264 0.033814288675785065\n",
      "265 0.03198729455471039\n",
      "266 0.030255302786827087\n",
      "267 0.028613636270165443\n",
      "268 0.02705821767449379\n",
      "269 0.025583643466234207\n",
      "270 0.024186180904507637\n",
      "271 0.02286272868514061\n",
      "272 0.0216091088950634\n",
      "273 0.020421558991074562\n",
      "274 0.019296525046229362\n",
      "275 0.018234070390462875\n",
      "276 0.01722882129251957\n",
      "277 0.016275014728307724\n",
      "278 0.015373142436146736\n",
      "279 0.014519657008349895\n",
      "280 0.013711531646549702\n",
      "281 0.012947090901434422\n",
      "282 0.01222376711666584\n",
      "283 0.011539556086063385\n",
      "284 0.01089223101735115\n",
      "285 0.010280754417181015\n",
      "286 0.009702670387923717\n",
      "287 0.009156310930848122\n",
      "288 0.008639907464385033\n",
      "289 0.008151804096996784\n",
      "290 0.007690311409533024\n",
      "291 0.007254073396325111\n",
      "292 0.006841903552412987\n",
      "293 0.006452745292335749\n",
      "294 0.006084918975830078\n",
      "295 0.005737630184739828\n",
      "296 0.0054096016101539135\n",
      "297 0.005099757574498653\n",
      "298 0.0048072244971990585\n",
      "299 0.004531179554760456\n",
      "300 0.0042704688385128975\n",
      "301 0.004024430178105831\n",
      "302 0.0037922044284641743\n",
      "303 0.003573032096028328\n",
      "304 0.003366223070770502\n",
      "305 0.0031711186747998\n",
      "306 0.0029870313592255116\n",
      "307 0.0028134232852607965\n",
      "308 0.002649666741490364\n",
      "309 0.002495230408385396\n",
      "310 0.002349594607949257\n",
      "311 0.0022123241797089577\n",
      "312 0.002082838909700513\n",
      "313 0.0019609015434980392\n",
      "314 0.0018458613194525242\n",
      "315 0.0017374650342389941\n",
      "316 0.0016352569218724966\n",
      "317 0.0015390138141810894\n",
      "318 0.0014482829719781876\n",
      "319 0.0013628534507006407\n",
      "320 0.0012823604047298431\n",
      "321 0.0012065173359587789\n",
      "322 0.0011350703425705433\n",
      "323 0.0010677989339455962\n",
      "324 0.0010044685332104564\n",
      "325 0.0009448115015402436\n",
      "326 0.0008886290015652776\n",
      "327 0.0008357223705388606\n",
      "328 0.0007859369507059455\n",
      "329 0.0007390576065517962\n",
      "330 0.0006949406233616173\n",
      "331 0.0006534018320962787\n",
      "332 0.000614302814938128\n",
      "333 0.0005775250028818846\n",
      "334 0.0005429089069366455\n",
      "335 0.0005103423609398305\n",
      "336 0.0004797243163920939\n",
      "337 0.00045090814819559455\n",
      "338 0.0004237947869114578\n",
      "339 0.0003983099013566971\n",
      "340 0.0003743287525139749\n",
      "341 0.00035176691017113626\n",
      "342 0.00033054829691536725\n",
      "343 0.0003105992800556123\n",
      "344 0.0002918315294664353\n",
      "345 0.00027420182595960796\n",
      "346 0.0002576073748059571\n",
      "347 0.00024201306223403662\n",
      "348 0.00022735967650078237\n",
      "349 0.0002135737013304606\n",
      "350 0.00020061196119058877\n",
      "351 0.0001884325611172244\n",
      "352 0.00017698212468530983\n",
      "353 0.00016622591647319496\n",
      "354 0.00015611093840561807\n",
      "355 0.00014660527813248336\n",
      "356 0.00013767153723165393\n",
      "357 0.00012927687203045934\n",
      "358 0.00012139310274505988\n",
      "359 0.00011397843627491966\n",
      "360 0.00010701546125346795\n",
      "361 0.00010046861279988661\n",
      "362 9.431936632608995e-05\n",
      "363 8.85453264345415e-05\n",
      "364 8.312016143463552e-05\n",
      "365 7.802036998327821e-05\n",
      "366 7.323319732677191e-05\n",
      "367 6.873302481835708e-05\n",
      "368 6.451096851378679e-05\n",
      "369 6.054055120330304e-05\n",
      "370 5.681600305251777e-05\n",
      "371 5.3313327953219414e-05\n",
      "372 5.002717807656154e-05\n",
      "373 4.69455735583324e-05\n",
      "374 4.4047967094229534e-05\n",
      "375 4.132591129746288e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 3.8770052924519405e-05\n",
      "377 3.637297049863264e-05\n",
      "378 3.41178456437774e-05\n",
      "379 3.200789069524035e-05\n",
      "380 3.0021308702998795e-05\n",
      "381 2.8158878194517456e-05\n",
      "382 2.6408746634842828e-05\n",
      "383 2.476986264809966e-05\n",
      "384 2.3228709324030206e-05\n",
      "385 2.1782507246825844e-05\n",
      "386 2.0427227354957722e-05\n",
      "387 1.9153581888531335e-05\n",
      "388 1.7957454474526457e-05\n",
      "389 1.6836327631608583e-05\n",
      "390 1.5783864000695758e-05\n",
      "391 1.4795539755141363e-05\n",
      "392 1.3868058886146173e-05\n",
      "393 1.3000928447581828e-05\n",
      "394 1.2184388651803602e-05\n",
      "395 1.1420086593716405e-05\n",
      "396 1.0701645805966109e-05\n",
      "397 1.0028332326328382e-05\n",
      "398 9.396957466378808e-06\n",
      "399 8.804320714261848e-06\n",
      "400 8.24918424768839e-06\n",
      "401 7.728336640866473e-06\n",
      "402 7.240387276397087e-06\n",
      "403 6.782225227652816e-06\n",
      "404 6.353176559059648e-06\n",
      "405 5.949931164650479e-06\n",
      "406 5.571591373154661e-06\n",
      "407 5.2187397159286775e-06\n",
      "408 4.886891929345438e-06\n",
      "409 4.574994363792939e-06\n",
      "410 4.283136149751954e-06\n",
      "411 4.010646989627276e-06\n",
      "412 3.7549618809862295e-06\n",
      "413 3.514284571792814e-06\n",
      "414 3.2900629776122514e-06\n",
      "415 3.078853524129954e-06\n",
      "416 2.8811591619160026e-06\n",
      "417 2.6968600650434382e-06\n",
      "418 2.522613158362219e-06\n",
      "419 2.3606003196618985e-06\n",
      "420 2.208378418799839e-06\n",
      "421 2.065978605969576e-06\n",
      "422 1.932425220729783e-06\n",
      "423 1.8077839740726631e-06\n",
      "424 1.6907449662539875e-06\n",
      "425 1.5808114994797506e-06\n",
      "426 1.4782307289351593e-06\n",
      "427 1.381999027216807e-06\n",
      "428 1.2924476777698146e-06\n",
      "429 1.2079706266376888e-06\n",
      "430 1.1290464954072377e-06\n",
      "431 1.0555741027928889e-06\n",
      "432 9.865984793577809e-07\n",
      "433 9.221100185641262e-07\n",
      "434 8.614469493295474e-07\n",
      "435 8.048851896091946e-07\n",
      "436 7.522996838815743e-07\n",
      "437 7.028258437458135e-07\n",
      "438 6.566370984728565e-07\n",
      "439 6.130565566309087e-07\n",
      "440 5.725647156396008e-07\n",
      "441 5.347120577425812e-07\n",
      "442 4.991015885025263e-07\n",
      "443 4.660105616949295e-07\n",
      "444 4.350459335000778e-07\n",
      "445 4.05891512400558e-07\n",
      "446 3.792054599216499e-07\n",
      "447 3.538546593517822e-07\n",
      "448 3.3024136314452335e-07\n",
      "449 3.0793131600148627e-07\n",
      "450 2.87362269091318e-07\n",
      "451 2.6789422236106475e-07\n",
      "452 2.499816957879375e-07\n",
      "453 2.3324496112309134e-07\n",
      "454 2.1740603983744222e-07\n",
      "455 2.0275174961170706e-07\n",
      "456 1.8902944987075898e-07\n",
      "457 1.7622983250475954e-07\n",
      "458 1.643603440015795e-07\n",
      "459 1.5307855960600136e-07\n",
      "460 1.4288190186562133e-07\n",
      "461 1.33112635580801e-07\n",
      "462 1.2406398752773384e-07\n",
      "463 1.1553834156075027e-07\n",
      "464 1.0760459900893693e-07\n",
      "465 1.0040771769581625e-07\n",
      "466 9.338004502978947e-08\n",
      "467 8.69838814310242e-08\n",
      "468 8.101107340507951e-08\n",
      "469 7.545197888703115e-08\n",
      "470 7.036805982352234e-08\n",
      "471 6.540081187722535e-08\n",
      "472 6.096950500023013e-08\n",
      "473 5.671332203860402e-08\n",
      "474 5.283338211370392e-08\n",
      "475 4.921574259242334e-08\n",
      "476 4.567741740402198e-08\n",
      "477 4.252572693985712e-08\n",
      "478 3.9545202668023194e-08\n",
      "479 3.683785365637959e-08\n",
      "480 3.4225656975195307e-08\n",
      "481 3.190445596601421e-08\n",
      "482 2.9671163304101356e-08\n",
      "483 2.7553905823651803e-08\n",
      "484 2.5596747832423716e-08\n",
      "485 2.3884570765630997e-08\n",
      "486 2.2182561565387005e-08\n",
      "487 2.0598120542558718e-08\n",
      "488 1.9179793753210106e-08\n",
      "489 1.7850844358235918e-08\n",
      "490 1.6605017805204625e-08\n",
      "491 1.5464209468518675e-08\n",
      "492 1.4401360104443484e-08\n",
      "493 1.3383441910264082e-08\n",
      "494 1.2444978381154215e-08\n",
      "495 1.1548339173828026e-08\n",
      "496 1.0719507947953844e-08\n",
      "497 9.978136539245952e-09\n",
      "498 9.319099270044262e-09\n",
      "499 8.62654037092625e-09\n"
     ]
    }
   ],
   "source": [
    "#   PyTorch中的optim包抽象出优化算法的思想，并提供常用优化算法的实现。\n",
    "#   其采用很多高级方法来获取更优的梯度方向并更新梯度。\n",
    "\n",
    "#    在这个例子中，我们将像以前一样使用nn包定义我们的模型，\n",
    "#    但我们将使用optim包提供的Adam算法优化模型：\n",
    "\n",
    "# Code in file nn/two_layer_net_optim.py\n",
    "import torch\n",
    " \n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    " \n",
    "# Create random Tensors to hold inputs and outputs.\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    " \n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H, D_out),\n",
    "        )\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    " \n",
    "# Use the optim package to define an Optimizer that will update the weights of\n",
    "# the model for us. Here we will use Adam; the optim package contains many other\n",
    "# optimization algoriths. The first argument to the Adam constructor tells the\n",
    "# optimizer which Tensors it should update.\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(500):\n",
    "  # Forward pass: compute predicted y by passing x to the model.\n",
    "  y_pred = model(x)\n",
    " \n",
    "  # Compute and print loss.\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  print(t, loss.item())\n",
    "  \n",
    "  # Before the backward pass, use the optimizer object to zero all of the\n",
    "  # gradients for the Tensors it will update (which are the learnable weights\n",
    "  # of the model)\n",
    "  optimizer.zero_grad()\n",
    " \n",
    "  # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "  loss.backward()\n",
    " \n",
    "  # Calling the step function on an Optimizer makes an update to its parameters\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 706.7421264648438\n",
      "1 656.128173828125\n",
      "2 612.373779296875\n",
      "3 573.9771728515625\n",
      "4 539.90625\n",
      "5 509.0140686035156\n",
      "6 481.1817626953125\n",
      "7 455.56658935546875\n",
      "8 432.02880859375\n",
      "9 410.1608581542969\n",
      "10 389.59515380859375\n",
      "11 370.27874755859375\n",
      "12 351.9056396484375\n",
      "13 334.4429626464844\n",
      "14 317.74468994140625\n",
      "15 301.78717041015625\n",
      "16 286.48565673828125\n",
      "17 271.8874816894531\n",
      "18 257.8059387207031\n",
      "19 244.3289794921875\n",
      "20 231.46481323242188\n",
      "21 219.14947509765625\n",
      "22 207.34396362304688\n",
      "23 196.06674194335938\n",
      "24 185.26617431640625\n",
      "25 174.8857879638672\n",
      "26 164.99172973632812\n",
      "27 155.5475616455078\n",
      "28 146.5657958984375\n",
      "29 138.02297973632812\n",
      "30 129.89414978027344\n",
      "31 122.2136001586914\n",
      "32 114.91441345214844\n",
      "33 108.01841735839844\n",
      "34 101.4728012084961\n",
      "35 95.29704284667969\n",
      "36 89.47154998779297\n",
      "37 83.98629760742188\n",
      "38 78.83023071289062\n",
      "39 73.99015045166016\n",
      "40 69.43306732177734\n",
      "41 65.15087127685547\n",
      "42 61.13054656982422\n",
      "43 57.34489059448242\n",
      "44 53.792930603027344\n",
      "45 50.470481872558594\n",
      "46 47.35105514526367\n",
      "47 44.4250602722168\n",
      "48 41.685874938964844\n",
      "49 39.120849609375\n",
      "50 36.71492004394531\n",
      "51 34.45984649658203\n",
      "52 32.34952163696289\n",
      "53 30.372154235839844\n",
      "54 28.51751708984375\n",
      "55 26.779916763305664\n",
      "56 25.151174545288086\n",
      "57 23.624853134155273\n",
      "58 22.19850730895996\n",
      "59 20.861194610595703\n",
      "60 19.60722541809082\n",
      "61 18.433334350585938\n",
      "62 17.334638595581055\n",
      "63 16.306116104125977\n",
      "64 15.342876434326172\n",
      "65 14.439604759216309\n",
      "66 13.593619346618652\n",
      "67 12.800338745117188\n",
      "68 12.053013801574707\n",
      "69 11.35289192199707\n",
      "70 10.695903778076172\n",
      "71 10.079646110534668\n",
      "72 9.502020835876465\n",
      "73 8.959446907043457\n",
      "74 8.45046615600586\n",
      "75 7.972192764282227\n",
      "76 7.5231733322143555\n",
      "77 7.101365566253662\n",
      "78 6.705105781555176\n",
      "79 6.332221984863281\n",
      "80 5.981628894805908\n",
      "81 5.652088165283203\n",
      "82 5.342321872711182\n",
      "83 5.05092191696167\n",
      "84 4.776400566101074\n",
      "85 4.51830530166626\n",
      "86 4.275026798248291\n",
      "87 4.045661926269531\n",
      "88 3.8291242122650146\n",
      "89 3.625247001647949\n",
      "90 3.43314790725708\n",
      "91 3.251798629760742\n",
      "92 3.0809383392333984\n",
      "93 2.9198060035705566\n",
      "94 2.767692804336548\n",
      "95 2.6240766048431396\n",
      "96 2.4883766174316406\n",
      "97 2.3603153228759766\n",
      "98 2.2393484115600586\n",
      "99 2.1250061988830566\n",
      "100 2.0171291828155518\n",
      "101 1.9154523611068726\n",
      "102 1.8192768096923828\n",
      "103 1.7282638549804688\n",
      "104 1.6421186923980713\n",
      "105 1.5605525970458984\n",
      "106 1.483324408531189\n",
      "107 1.4103503227233887\n",
      "108 1.3412041664123535\n",
      "109 1.2755974531173706\n",
      "110 1.2134740352630615\n",
      "111 1.1545661687850952\n",
      "112 1.098750114440918\n",
      "113 1.0458687543869019\n",
      "114 0.9957587122917175\n",
      "115 0.9481562972068787\n",
      "116 0.9030418992042542\n",
      "117 0.8602548837661743\n",
      "118 0.8196693062782288\n",
      "119 0.7810938954353333\n",
      "120 0.7444155812263489\n",
      "121 0.7095707654953003\n",
      "122 0.6765667796134949\n",
      "123 0.6451994776725769\n",
      "124 0.6153543591499329\n",
      "125 0.5869680047035217\n",
      "126 0.5599632859230042\n",
      "127 0.5342822074890137\n",
      "128 0.5098684430122375\n",
      "129 0.4866226613521576\n",
      "130 0.46449512243270874\n",
      "131 0.4434087872505188\n",
      "132 0.4233302175998688\n",
      "133 0.4042089879512787\n",
      "134 0.3859906494617462\n",
      "135 0.3686579763889313\n",
      "136 0.3521547317504883\n",
      "137 0.3364276885986328\n",
      "138 0.3214000463485718\n",
      "139 0.3070913255214691\n",
      "140 0.29345640540122986\n",
      "141 0.2804715633392334\n",
      "142 0.26806366443634033\n",
      "143 0.2562428116798401\n",
      "144 0.2449600249528885\n",
      "145 0.23420600593090057\n",
      "146 0.22393780946731567\n",
      "147 0.21415047347545624\n",
      "148 0.20480266213417053\n",
      "149 0.19588497281074524\n",
      "150 0.18736927211284637\n",
      "151 0.17924398183822632\n",
      "152 0.17149795591831207\n",
      "153 0.1640935093164444\n",
      "154 0.15701591968536377\n",
      "155 0.15026138722896576\n",
      "156 0.14381352066993713\n",
      "157 0.13764695823192596\n",
      "158 0.1317550539970398\n",
      "159 0.12613545358181\n",
      "160 0.12077142298221588\n",
      "161 0.11563784629106522\n",
      "162 0.11073227226734161\n",
      "163 0.10604052990674973\n",
      "164 0.1015622615814209\n",
      "165 0.09727802872657776\n",
      "166 0.09317964315414429\n",
      "167 0.0892622172832489\n",
      "168 0.08552053570747375\n",
      "169 0.08193967491388321\n",
      "170 0.0785171315073967\n",
      "171 0.07523739337921143\n",
      "172 0.07209960371255875\n",
      "173 0.06909918040037155\n",
      "174 0.06623157858848572\n",
      "175 0.06348837912082672\n",
      "176 0.060861386358737946\n",
      "177 0.058346226811409\n",
      "178 0.055938784033060074\n",
      "179 0.053636133670806885\n",
      "180 0.05143086612224579\n",
      "181 0.049320120364427567\n",
      "182 0.04729943722486496\n",
      "183 0.04536597058176994\n",
      "184 0.04351653903722763\n",
      "185 0.04174700379371643\n",
      "186 0.040051672607660294\n",
      "187 0.038428861647844315\n",
      "188 0.03687770664691925\n",
      "189 0.03539564833045006\n",
      "190 0.03397585079073906\n",
      "191 0.03261426091194153\n",
      "192 0.03131166845560074\n",
      "193 0.030063411220908165\n",
      "194 0.028865095227956772\n",
      "195 0.02771741896867752\n",
      "196 0.026618320494890213\n",
      "197 0.025563575327396393\n",
      "198 0.02455199882388115\n",
      "199 0.023582376539707184\n",
      "200 0.022652532905340195\n",
      "201 0.021760493516921997\n",
      "202 0.020904410630464554\n",
      "203 0.020083969458937645\n",
      "204 0.01929694600403309\n",
      "205 0.01854204200208187\n",
      "206 0.01781906932592392\n",
      "207 0.01712457276880741\n",
      "208 0.01645810157060623\n",
      "209 0.015818428248167038\n",
      "210 0.015205432660877705\n",
      "211 0.014616826549172401\n",
      "212 0.014051458798348904\n",
      "213 0.013509159907698631\n",
      "214 0.012988145463168621\n",
      "215 0.012488112784922123\n",
      "216 0.012008409947156906\n",
      "217 0.011547335423529148\n",
      "218 0.011104855686426163\n",
      "219 0.010679700411856174\n",
      "220 0.010271799750626087\n",
      "221 0.009879966266453266\n",
      "222 0.009503609500825405\n",
      "223 0.00914206076413393\n",
      "224 0.008795063942670822\n",
      "225 0.008461637422442436\n",
      "226 0.008141226135194302\n",
      "227 0.007833491079509258\n",
      "228 0.007537941914051771\n",
      "229 0.0072540100663900375\n",
      "230 0.006980935577303171\n",
      "231 0.006718514487147331\n",
      "232 0.006466439459472895\n",
      "233 0.006224139127880335\n",
      "234 0.005991637706756592\n",
      "235 0.005768034607172012\n",
      "236 0.005553009919822216\n",
      "237 0.005346219055354595\n",
      "238 0.005147263407707214\n",
      "239 0.004956135991960764\n",
      "240 0.004772447980940342\n",
      "241 0.004595737438648939\n",
      "242 0.004425765480846167\n",
      "243 0.0042624035850167274\n",
      "244 0.004105248022824526\n",
      "245 0.003954022191464901\n",
      "246 0.003808657405897975\n",
      "247 0.003668815130367875\n",
      "248 0.003534543327987194\n",
      "249 0.003405149793252349\n",
      "250 0.0032806985545903444\n",
      "251 0.003161030588671565\n",
      "252 0.0030459125991910696\n",
      "253 0.0029350630939006805\n",
      "254 0.0028283586725592613\n",
      "255 0.0027257478795945644\n",
      "256 0.0026271084789186716\n",
      "257 0.0025321561843156815\n",
      "258 0.0024408060126006603\n",
      "259 0.002352809999138117\n",
      "260 0.0022681851405650377\n",
      "261 0.0021868387702852488\n",
      "262 0.0021084477193653584\n",
      "263 0.0020329293329268694\n",
      "264 0.0019601911772042513\n",
      "265 0.0018900824943557382\n",
      "266 0.0018225947860628366\n",
      "267 0.0017576786922290921\n",
      "268 0.0016951411962509155\n",
      "269 0.0016348668141290545\n",
      "270 0.0015770446043461561\n",
      "271 0.0015212814323604107\n",
      "272 0.0014675968559458852\n",
      "273 0.0014158874982967973\n",
      "274 0.0013660963159054518\n",
      "275 0.0013180342502892017\n",
      "276 0.001271803048439324\n",
      "277 0.001227203174494207\n",
      "278 0.0011842403328046203\n",
      "279 0.0011428669095039368\n",
      "280 0.0011030161986127496\n",
      "281 0.0010645970469340682\n",
      "282 0.0010275366948917508\n",
      "283 0.0009918230352923274\n",
      "284 0.0009573836578056216\n",
      "285 0.0009242052910849452\n",
      "286 0.000892187817953527\n",
      "287 0.0008613627287559211\n",
      "288 0.0008316182065755129\n",
      "289 0.0008029970340430737\n",
      "290 0.0007753822719678283\n",
      "291 0.0007487067487090826\n",
      "292 0.0007229939801618457\n",
      "293 0.0006982111372053623\n",
      "294 0.0006742877303622663\n",
      "295 0.0006512370891869068\n",
      "296 0.0006289812736213207\n",
      "297 0.0006075161509215832\n",
      "298 0.0005868072039447725\n",
      "299 0.0005668502999469638\n",
      "300 0.0005475957877933979\n",
      "301 0.0005290224216878414\n",
      "302 0.0005110851489007473\n",
      "303 0.0004937747726216912\n",
      "304 0.00047708864440210164\n",
      "305 0.0004609841853380203\n",
      "306 0.00044544145930558443\n",
      "307 0.00043045025086030364\n",
      "308 0.00041596998926252127\n",
      "309 0.0004019989864900708\n",
      "310 0.0003885248734150082\n",
      "311 0.00037550844717770815\n",
      "312 0.00036294455640017986\n",
      "313 0.0003508137306198478\n",
      "314 0.00033910677302628756\n",
      "315 0.00032778995227999985\n",
      "316 0.00031687977025285363\n",
      "317 0.00030634249560534954\n",
      "318 0.00029617748805321753\n",
      "319 0.00028636076604016125\n",
      "320 0.0002768763224594295\n",
      "321 0.0002677184238564223\n",
      "322 0.0002588789211586118\n",
      "323 0.00025033875135704875\n",
      "324 0.00024207141541410238\n",
      "325 0.00023410143330693245\n",
      "326 0.00022639453527517617\n",
      "327 0.00021895811369176954\n",
      "328 0.00021178057068027556\n",
      "329 0.00020483223488554358\n",
      "330 0.00019813934341073036\n",
      "331 0.00019167129357811064\n",
      "332 0.00018541303870733827\n",
      "333 0.00017937374650500715\n",
      "334 0.00017353062867186964\n",
      "335 0.00016788301581982523\n",
      "336 0.00016242815763689578\n",
      "337 0.0001571561151649803\n",
      "338 0.000152064225403592\n",
      "339 0.00014714627468492836\n",
      "340 0.00014238720177672803\n",
      "341 0.00013778480933979154\n",
      "342 0.00013334381219465286\n",
      "343 0.00012904895993415266\n",
      "344 0.0001248940679943189\n",
      "345 0.000120889613754116\n",
      "346 0.00011700760660460219\n",
      "347 0.00011325429659336805\n",
      "348 0.00010962984379148111\n",
      "349 0.00010611776815494522\n",
      "350 0.00010272726649418473\n",
      "351 9.944818157237023e-05\n",
      "352 9.627987310523167e-05\n",
      "353 9.320961544290185e-05\n",
      "354 9.02428146218881e-05\n",
      "355 8.73760727699846e-05\n",
      "356 8.46028997329995e-05\n",
      "357 8.19235501694493e-05\n",
      "358 7.932508742669597e-05\n",
      "359 7.681785064050928e-05\n",
      "360 7.439110049745068e-05\n",
      "361 7.204119901871309e-05\n",
      "362 6.976794975344092e-05\n",
      "363 6.75689589115791e-05\n",
      "364 6.544079951709136e-05\n",
      "365 6.338963430607691e-05\n",
      "366 6.139949982753024e-05\n",
      "367 5.94736666243989e-05\n",
      "368 5.761069405707531e-05\n",
      "369 5.5806045565987006e-05\n",
      "370 5.406259879237041e-05\n",
      "371 5.237647928879596e-05\n",
      "372 5.074207729194313e-05\n",
      "373 4.916190300718881e-05\n",
      "374 4.7632071073167026e-05\n",
      "375 4.614789577317424e-05\n",
      "376 4.4720214646076784e-05\n",
      "377 4.333020842750557e-05\n",
      "378 4.1985618736362085e-05\n",
      "379 4.0686358261154965e-05\n",
      "380 3.942735929740593e-05\n",
      "381 3.820767597062513e-05\n",
      "382 3.703264519572258e-05\n",
      "383 3.589113475754857e-05\n",
      "384 3.477936843410134e-05\n",
      "385 3.3711308788042516e-05\n",
      "386 3.2677726267138496e-05\n",
      "387 3.167249815305695e-05\n",
      "388 3.0701030482305214e-05\n",
      "389 2.975955248984974e-05\n",
      "390 2.8846798159065656e-05\n",
      "391 2.796561602735892e-05\n",
      "392 2.7110665541840717e-05\n",
      "393 2.62792018475011e-05\n",
      "394 2.547877920733299e-05\n",
      "395 2.470454273861833e-05\n",
      "396 2.3954606149345636e-05\n",
      "397 2.3226080884342082e-05\n",
      "398 2.2520271159010008e-05\n",
      "399 2.183688775403425e-05\n",
      "400 2.117553594871424e-05\n",
      "401 2.0531755581032485e-05\n",
      "402 1.9911436538677663e-05\n",
      "403 1.9309376511955634e-05\n",
      "404 1.8725429981714115e-05\n",
      "405 1.8160520994570106e-05\n",
      "406 1.7611158909858204e-05\n",
      "407 1.7082937119994313e-05\n",
      "408 1.6567977581871673e-05\n",
      "409 1.6071049685706384e-05\n",
      "410 1.5588157111778855e-05\n",
      "411 1.5120783245947678e-05\n",
      "412 1.4665360140497796e-05\n",
      "413 1.4225348422769457e-05\n",
      "414 1.3802011380903423e-05\n",
      "415 1.3389212654146831e-05\n",
      "416 1.2987231457373127e-05\n",
      "417 1.260135650227312e-05\n",
      "418 1.2226089893374592e-05\n",
      "419 1.1861540770041756e-05\n",
      "420 1.1507726412673946e-05\n",
      "421 1.1164415809616912e-05\n",
      "422 1.0833239684870932e-05\n",
      "423 1.0511256732570473e-05\n",
      "424 1.0200507858826313e-05\n",
      "425 9.897133168124128e-06\n",
      "426 9.602869795344304e-06\n",
      "427 9.320197023043875e-06\n",
      "428 9.042235433298629e-06\n",
      "429 8.775895366852637e-06\n",
      "430 8.518410140823107e-06\n",
      "431 8.266424629255198e-06\n",
      "432 8.022625479497947e-06\n",
      "433 7.785915840941016e-06\n",
      "434 7.556484888482373e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435 7.3355140557396226e-06\n",
      "436 7.119142537703738e-06\n",
      "437 6.91042350808857e-06\n",
      "438 6.707799002469983e-06\n",
      "439 6.510881576105021e-06\n",
      "440 6.319968633761164e-06\n",
      "441 6.136096089903731e-06\n",
      "442 5.9554859035415575e-06\n",
      "443 5.782007974630687e-06\n",
      "444 5.612937002297258e-06\n",
      "445 5.449127456813585e-06\n",
      "446 5.289417003950803e-06\n",
      "447 5.136986601428362e-06\n",
      "448 4.987489319319138e-06\n",
      "449 4.842167982133105e-06\n",
      "450 4.70160057375324e-06\n",
      "451 4.564796199701959e-06\n",
      "452 4.4323555812297855e-06\n",
      "453 4.304361027607229e-06\n",
      "454 4.179496045253472e-06\n",
      "455 4.0578261177870445e-06\n",
      "456 3.939996986446204e-06\n",
      "457 3.827463388006436e-06\n",
      "458 3.715929324243916e-06\n",
      "459 3.60977060154255e-06\n",
      "460 3.5056204978900496e-06\n",
      "461 3.403970595172723e-06\n",
      "462 3.305285190435825e-06\n",
      "463 3.210499471606454e-06\n",
      "464 3.118645508948248e-06\n",
      "465 3.028424998774426e-06\n",
      "466 2.941754701168975e-06\n",
      "467 2.8571434995683376e-06\n",
      "468 2.7754861093853833e-06\n",
      "469 2.695406692510005e-06\n",
      "470 2.6181971861660713e-06\n",
      "471 2.543077243899461e-06\n",
      "472 2.470536401233403e-06\n",
      "473 2.4002345071494346e-06\n",
      "474 2.331207269890001e-06\n",
      "475 2.264773456772673e-06\n",
      "476 2.2004519451002125e-06\n",
      "477 2.1373464278440224e-06\n",
      "478 2.07646598937572e-06\n",
      "479 2.0173354187136283e-06\n",
      "480 1.959758265002165e-06\n",
      "481 1.9040087408939144e-06\n",
      "482 1.8497495375413564e-06\n",
      "483 1.7971519810089376e-06\n",
      "484 1.7459286709708977e-06\n",
      "485 1.6966516795946518e-06\n",
      "486 1.6486596905451734e-06\n",
      "487 1.6019839677028358e-06\n",
      "488 1.5564564819214866e-06\n",
      "489 1.5123458751986618e-06\n",
      "490 1.4699626262881793e-06\n",
      "491 1.4282340998761356e-06\n",
      "492 1.3878012623536051e-06\n",
      "493 1.3489247976394836e-06\n",
      "494 1.3106379128657863e-06\n",
      "495 1.2736600183416158e-06\n",
      "496 1.237915967067238e-06\n",
      "497 1.2032062386424514e-06\n",
      "498 1.168903963844059e-06\n",
      "499 1.1364031706762034e-06\n"
     ]
    }
   ],
   "source": [
    "#PyTorch: Custom nn Modules\n",
    "    #有时需要指定比现有模块序列更复杂的模型；对于这些情况，\n",
    "    #可以通过子类化nn.Module定义自己的模块，并定义一个接收输入Tensor的forward，\n",
    "    #并使用其他模块或Tensor上的其他autograd操作生成输出Tensor。\n",
    "\n",
    "   #在这个例子中，我们将以自定义Module子类的形式实现2层网络：\n",
    "\n",
    "\n",
    "# Code in file nn/two_layer_net_module.py\n",
    "import torch\n",
    " \n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "  def __init__(self, D_in, H, D_out):\n",
    "    \"\"\"\n",
    "    In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "    member variables.\n",
    "    \"\"\"\n",
    "    super(TwoLayerNet, self).__init__()\n",
    "    self.linear1 = torch.nn.Linear(D_in, H)\n",
    "    self.linear2 = torch.nn.Linear(H, D_out)\n",
    " \n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    In the forward function we accept a Tensor of input data and we must return\n",
    "    a Tensor of output data. We can use Modules defined in the constructor as\n",
    "    well as arbitrary (differentiable) operations on Tensors.\n",
    "    \"\"\"\n",
    "    h_relu = self.linear1(x).clamp(min=0)\n",
    "    y_pred = self.linear2(h_relu)\n",
    "    return y_pred\n",
    " \n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    " \n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    " \n",
    "# Construct our model by instantiating the class defined above.\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    " \n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "for t in range(500):\n",
    "  # Forward pass: Compute predicted y by passing x to the model\n",
    "  y_pred = model(x)\n",
    " \n",
    "  # Compute and print loss\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  print(t, loss.item())\n",
    " \n",
    "  # Zero gradients, perform a backward pass, and update the weights.\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 713.18603515625\n",
      "1 740.5426635742188\n",
      "2 698.7960205078125\n",
      "3 696.6361694335938\n",
      "4 590.2883911132812\n",
      "5 691.9925537109375\n",
      "6 469.714599609375\n",
      "7 689.7020874023438\n",
      "8 359.3372802734375\n",
      "9 306.2121276855469\n",
      "10 683.88232421875\n",
      "11 657.9124145507812\n",
      "12 647.6469116210938\n",
      "13 626.8375854492188\n",
      "14 141.60354614257812\n",
      "15 567.3827514648438\n",
      "16 667.035400390625\n",
      "17 92.56871032714844\n",
      "18 460.34869384765625\n",
      "19 76.26693725585938\n",
      "20 385.497802734375\n",
      "21 343.85101318359375\n",
      "22 296.329833984375\n",
      "23 107.47029113769531\n",
      "24 207.9883575439453\n",
      "25 499.7738037109375\n",
      "26 142.9925994873047\n",
      "27 141.30697631835938\n",
      "28 128.86427307128906\n",
      "29 353.2174377441406\n",
      "30 487.99383544921875\n",
      "31 270.0692138671875\n",
      "32 374.9713439941406\n",
      "33 70.34030151367188\n",
      "34 61.364845275878906\n",
      "35 270.6654357910156\n",
      "36 39.874290466308594\n",
      "37 36.63257598876953\n",
      "38 300.88623046875\n",
      "39 28.848243713378906\n",
      "40 323.704345703125\n",
      "41 119.5709457397461\n",
      "42 290.1915283203125\n",
      "43 127.08360290527344\n",
      "44 94.26490020751953\n",
      "45 95.5934829711914\n",
      "46 218.3485870361328\n",
      "47 194.7862548828125\n",
      "48 275.64691162109375\n",
      "49 241.48118591308594\n",
      "50 211.65432739257812\n",
      "51 182.20651245117188\n",
      "52 164.2731170654297\n",
      "53 119.47733306884766\n",
      "54 208.09593200683594\n",
      "55 167.00918579101562\n",
      "56 55.63243103027344\n",
      "57 147.23443603515625\n",
      "58 331.0911865234375\n",
      "59 66.97362518310547\n",
      "60 273.0352783203125\n",
      "61 116.92668914794922\n",
      "62 305.7013854980469\n",
      "63 93.69564819335938\n",
      "64 173.92306518554688\n",
      "65 134.92352294921875\n",
      "66 106.2801284790039\n",
      "67 120.55262756347656\n",
      "68 107.44070434570312\n",
      "69 100.16029357910156\n",
      "70 87.7514877319336\n",
      "71 273.8084716796875\n",
      "72 59.67496109008789\n",
      "73 120.57942199707031\n",
      "74 51.884918212890625\n",
      "75 55.39083480834961\n",
      "76 55.85881423950195\n",
      "77 50.3206787109375\n",
      "78 105.56338500976562\n",
      "79 32.93061828613281\n",
      "80 69.98275756835938\n",
      "81 160.9348602294922\n",
      "82 39.43588638305664\n",
      "83 20.73189353942871\n",
      "84 125.86295318603516\n",
      "85 55.069618225097656\n",
      "86 21.844406127929688\n",
      "87 81.89614868164062\n",
      "88 22.2979736328125\n",
      "89 31.528200149536133\n",
      "90 18.61467170715332\n",
      "91 17.436790466308594\n",
      "92 18.23196029663086\n",
      "93 17.706092834472656\n",
      "94 77.81707000732422\n",
      "95 16.721149444580078\n",
      "96 42.31238555908203\n",
      "97 12.310037612915039\n",
      "98 21.78807258605957\n",
      "99 32.53837585449219\n",
      "100 29.992490768432617\n",
      "101 20.840530395507812\n",
      "102 18.753816604614258\n",
      "103 14.98776912689209\n",
      "104 11.245800971984863\n",
      "105 17.49834632873535\n",
      "106 13.58718204498291\n",
      "107 18.267871856689453\n",
      "108 11.892165184020996\n",
      "109 13.932042121887207\n",
      "110 17.72739028930664\n",
      "111 10.852007865905762\n",
      "112 5.988162040710449\n",
      "113 11.748880386352539\n",
      "114 6.723808288574219\n",
      "115 5.989605903625488\n",
      "116 14.478616714477539\n",
      "117 4.2291364669799805\n",
      "118 16.797788619995117\n",
      "119 8.098849296569824\n",
      "120 7.456132888793945\n",
      "121 6.574954986572266\n",
      "122 7.0857367515563965\n",
      "123 8.769918441772461\n",
      "124 5.653038501739502\n",
      "125 5.699625015258789\n",
      "126 3.8606250286102295\n",
      "127 20.268157958984375\n",
      "128 15.223091125488281\n",
      "129 11.448614120483398\n",
      "130 2.4704856872558594\n",
      "131 11.006121635437012\n",
      "132 2.454288959503174\n",
      "133 18.218843460083008\n",
      "134 8.509084701538086\n",
      "135 9.086236000061035\n",
      "136 9.850915908813477\n",
      "137 9.096699714660645\n",
      "138 8.660579681396484\n",
      "139 10.552682876586914\n",
      "140 3.3508565425872803\n",
      "141 9.20486068725586\n",
      "142 3.3017210960388184\n",
      "143 18.811134338378906\n",
      "144 2.400557041168213\n",
      "145 3.443033218383789\n",
      "146 11.384546279907227\n",
      "147 3.3158981800079346\n",
      "148 2.090212821960449\n",
      "149 4.8497724533081055\n",
      "150 1.664651870727539\n",
      "151 5.076507568359375\n",
      "152 4.927452564239502\n",
      "153 2.4815261363983154\n",
      "154 4.753735542297363\n",
      "155 8.03938102722168\n",
      "156 2.9151358604431152\n",
      "157 5.907118797302246\n",
      "158 3.1801064014434814\n",
      "159 4.932723045349121\n",
      "160 10.501897811889648\n",
      "161 2.7611024379730225\n",
      "162 2.0786192417144775\n",
      "163 5.347956657409668\n",
      "164 9.356405258178711\n",
      "165 2.4576878547668457\n",
      "166 7.897889137268066\n",
      "167 3.885529041290283\n",
      "168 3.302244186401367\n",
      "169 6.065003395080566\n",
      "170 1.764307975769043\n",
      "171 2.4498279094696045\n",
      "172 3.0440316200256348\n",
      "173 3.5596418380737305\n",
      "174 2.768857955932617\n",
      "175 1.606584072113037\n",
      "176 4.14505672454834\n",
      "177 4.0154619216918945\n",
      "178 2.4959073066711426\n",
      "179 2.0129597187042236\n",
      "180 1.6623961925506592\n",
      "181 1.1921814680099487\n",
      "182 5.7798566818237305\n",
      "183 2.2026939392089844\n",
      "184 0.9546816349029541\n",
      "185 2.0828747749328613\n",
      "186 1.6001734733581543\n",
      "187 0.8334690928459167\n",
      "188 3.3285412788391113\n",
      "189 1.126825213432312\n",
      "190 2.7531824111938477\n",
      "191 2.23508882522583\n",
      "192 0.9442195892333984\n",
      "193 1.3757052421569824\n",
      "194 1.9329888820648193\n",
      "195 1.7568687200546265\n",
      "196 0.8095095157623291\n",
      "197 0.7417747974395752\n",
      "198 1.3429378271102905\n",
      "199 1.2113265991210938\n",
      "200 1.0264406204223633\n",
      "201 1.1135939359664917\n",
      "202 1.1047873497009277\n",
      "203 0.5881249904632568\n",
      "204 0.5852290391921997\n",
      "205 4.511900901794434\n",
      "206 0.8778401017189026\n",
      "207 0.9278950691223145\n",
      "208 0.587517499923706\n",
      "209 1.1730403900146484\n",
      "210 1.5751028060913086\n",
      "211 0.35426825284957886\n",
      "212 0.7976872324943542\n",
      "213 3.2765109539031982\n",
      "214 0.6569881439208984\n",
      "215 3.118314504623413\n",
      "216 0.9072224497795105\n",
      "217 0.3838730454444885\n",
      "218 0.9253827929496765\n",
      "219 0.25364428758621216\n",
      "220 1.273068904876709\n",
      "221 1.499400019645691\n",
      "222 0.25073516368865967\n",
      "223 0.5188990831375122\n",
      "224 0.24470441043376923\n",
      "225 0.22632840275764465\n",
      "226 1.689929723739624\n",
      "227 0.49387243390083313\n",
      "228 0.40488922595977783\n",
      "229 0.2758798897266388\n",
      "230 1.1022331714630127\n",
      "231 0.5926804542541504\n",
      "232 0.34279805421829224\n",
      "233 0.4054587781429291\n",
      "234 0.3807017207145691\n",
      "235 0.3789404630661011\n",
      "236 0.3423757553100586\n",
      "237 0.18025192618370056\n",
      "238 0.2828470468521118\n",
      "239 0.16580477356910706\n",
      "240 0.23402279615402222\n",
      "241 3.5815317630767822\n",
      "242 1.4661195278167725\n",
      "243 1.5032716989517212\n",
      "244 3.032005786895752\n",
      "245 0.1768610030412674\n",
      "246 0.5917128920555115\n",
      "247 0.2612001597881317\n",
      "248 1.2744054794311523\n",
      "249 0.22288766503334045\n",
      "250 0.9526561498641968\n",
      "251 2.2274088859558105\n",
      "252 2.155137062072754\n",
      "253 1.3065447807312012\n",
      "254 0.44229406118392944\n",
      "255 1.1254031658172607\n",
      "256 2.180699110031128\n",
      "257 0.18847888708114624\n",
      "258 1.1301991939544678\n",
      "259 1.4871578216552734\n",
      "260 0.6933909058570862\n",
      "261 1.045654535293579\n",
      "262 1.3828938007354736\n",
      "263 0.23120245337486267\n",
      "264 0.9692273736000061\n",
      "265 0.8705315589904785\n",
      "266 1.4073430299758911\n",
      "267 0.9147657155990601\n",
      "268 0.21555018424987793\n",
      "269 1.396998405456543\n",
      "270 0.7458223700523376\n",
      "271 0.18310779333114624\n",
      "272 0.1668671816587448\n",
      "273 1.3552021980285645\n",
      "274 0.13362854719161987\n",
      "275 0.9794177412986755\n",
      "276 0.6847742795944214\n",
      "277 0.5941179990768433\n",
      "278 0.9464343786239624\n",
      "279 0.4860062897205353\n",
      "280 0.13256850838661194\n",
      "281 0.8424737453460693\n",
      "282 0.3256210684776306\n",
      "283 1.7390031814575195\n",
      "284 1.7092328071594238\n",
      "285 0.40094825625419617\n",
      "286 0.6684759259223938\n",
      "287 0.1571195423603058\n",
      "288 0.1437288075685501\n",
      "289 0.6505009531974792\n",
      "290 1.8116495609283447\n",
      "291 1.286103367805481\n",
      "292 0.7593511343002319\n",
      "293 2.0696709156036377\n",
      "294 0.8293420076370239\n",
      "295 1.5400750637054443\n",
      "296 0.8002933263778687\n",
      "297 1.1571868658065796\n",
      "298 0.8544408082962036\n",
      "299 1.0372668504714966\n",
      "300 1.2850314378738403\n",
      "301 0.6465432643890381\n",
      "302 0.2648359537124634\n",
      "303 2.6225388050079346\n",
      "304 0.5215429067611694\n",
      "305 1.033092975616455\n",
      "306 3.8547310829162598\n",
      "307 0.5365587472915649\n",
      "308 1.6822484731674194\n",
      "309 1.2618519067764282\n",
      "310 1.0825623273849487\n",
      "311 0.7884964942932129\n",
      "312 0.28424423933029175\n",
      "313 1.0351707935333252\n",
      "314 0.8507055640220642\n",
      "315 0.45678800344467163\n",
      "316 0.5359962582588196\n",
      "317 0.770984411239624\n",
      "318 0.6926591396331787\n",
      "319 0.44100409746170044\n",
      "320 1.3757565021514893\n",
      "321 0.48967257142066956\n",
      "322 0.2979115843772888\n",
      "323 0.721676230430603\n",
      "324 0.6135371327400208\n",
      "325 0.3010627031326294\n",
      "326 1.5898797512054443\n",
      "327 0.30719250440597534\n",
      "328 0.44871947169303894\n",
      "329 1.7176613807678223\n",
      "330 0.6138103604316711\n",
      "331 0.32512083649635315\n",
      "332 0.46227455139160156\n",
      "333 0.42868584394454956\n",
      "334 1.0604162216186523\n",
      "335 0.6224240064620972\n",
      "336 0.5001294016838074\n",
      "337 1.3213809728622437\n",
      "338 0.21201910078525543\n",
      "339 0.4273953437805176\n",
      "340 0.6435231566429138\n",
      "341 1.545823574066162\n",
      "342 0.29341602325439453\n",
      "343 0.7230263352394104\n",
      "344 1.9027706384658813\n",
      "345 0.5327364802360535\n",
      "346 0.4488164186477661\n",
      "347 0.9921457171440125\n",
      "348 0.52744060754776\n",
      "349 0.2698594331741333\n",
      "350 0.5846588611602783\n",
      "351 0.27413424849510193\n",
      "352 0.31413257122039795\n",
      "353 0.6103041768074036\n",
      "354 0.24937096238136292\n",
      "355 0.4991782307624817\n",
      "356 0.257147878408432\n",
      "357 0.14596185088157654\n",
      "358 1.8432680368423462\n",
      "359 0.22273866832256317\n",
      "360 1.2778873443603516\n",
      "361 0.517437219619751\n",
      "362 0.4819909930229187\n",
      "363 0.42626136541366577\n",
      "364 0.40332937240600586\n",
      "365 0.9089856743812561\n",
      "366 0.5002962946891785\n",
      "367 0.913378894329071\n",
      "368 0.5496665835380554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369 0.48392876982688904\n",
      "370 0.2869832217693329\n",
      "371 0.13312095403671265\n",
      "372 3.0087881088256836\n",
      "373 0.4114905893802643\n",
      "374 0.4114648699760437\n",
      "375 3.425373077392578\n",
      "376 1.395589828491211\n",
      "377 1.0489051342010498\n",
      "378 1.4234964847564697\n",
      "379 1.4486114978790283\n",
      "380 3.778827667236328\n",
      "381 0.127614364027977\n",
      "382 3.151441812515259\n",
      "383 2.7122342586517334\n",
      "384 0.3462696373462677\n",
      "385 0.1545257419347763\n",
      "386 1.2512799501419067\n",
      "387 0.9746799468994141\n",
      "388 1.0821336507797241\n",
      "389 1.4734206199645996\n",
      "390 1.253603219985962\n",
      "391 0.6555903553962708\n",
      "392 0.1723790466785431\n",
      "393 3.290722370147705\n",
      "394 0.8648631572723389\n",
      "395 1.615875005722046\n",
      "396 2.220625877380371\n",
      "397 5.768775939941406\n",
      "398 1.457713007926941\n",
      "399 0.2519408166408539\n",
      "400 0.6289272308349609\n",
      "401 1.1503187417984009\n",
      "402 5.990814685821533\n",
      "403 0.34729140996932983\n",
      "404 0.9311034679412842\n",
      "405 0.5965750813484192\n",
      "406 8.903633117675781\n",
      "407 0.12437552958726883\n",
      "408 1.676486849784851\n",
      "409 3.317774772644043\n",
      "410 1.8032708168029785\n",
      "411 1.247710943222046\n",
      "412 4.4474005699157715\n",
      "413 0.49091655015945435\n",
      "414 1.200745940208435\n",
      "415 0.7838289737701416\n",
      "416 0.7419627904891968\n",
      "417 0.5411570072174072\n",
      "418 0.845346212387085\n",
      "419 0.4715774357318878\n",
      "420 0.7084864974021912\n",
      "421 0.6054607629776001\n",
      "422 1.0439207553863525\n",
      "423 0.4047544002532959\n",
      "424 0.47576895356178284\n",
      "425 1.5623103380203247\n",
      "426 0.34598520398139954\n",
      "427 0.6084727644920349\n",
      "428 0.3564230501651764\n",
      "429 1.6794575452804565\n",
      "430 0.29465293884277344\n",
      "431 0.873535692691803\n",
      "432 0.7229025959968567\n",
      "433 0.8189002275466919\n",
      "434 0.3482022285461426\n",
      "435 0.19623835384845734\n",
      "436 1.545196771621704\n",
      "437 0.965060830116272\n",
      "438 0.9203757643699646\n",
      "439 0.39809879660606384\n",
      "440 0.46225857734680176\n",
      "441 0.34379875659942627\n",
      "442 0.5543667674064636\n",
      "443 0.39728087186813354\n",
      "444 0.9323636889457703\n",
      "445 0.6533759236335754\n",
      "446 1.8622307777404785\n",
      "447 1.51328706741333\n",
      "448 0.6698608994483948\n",
      "449 0.7979562878608704\n",
      "450 0.786022424697876\n",
      "451 1.425539493560791\n",
      "452 2.4629440307617188\n",
      "453 0.5391095876693726\n",
      "454 2.2094290256500244\n",
      "455 1.6732746362686157\n",
      "456 0.5994720458984375\n",
      "457 1.4321638345718384\n",
      "458 2.0190467834472656\n",
      "459 0.46126243472099304\n",
      "460 0.16683344542980194\n",
      "461 7.607313632965088\n",
      "462 0.17239727079868317\n",
      "463 0.5875986814498901\n",
      "464 6.279278755187988\n",
      "465 1.6387197971343994\n",
      "466 0.43051275610923767\n",
      "467 11.329103469848633\n",
      "468 1.1165839433670044\n",
      "469 0.4162229895591736\n",
      "470 2.9355597496032715\n",
      "471 9.214847564697266\n",
      "472 0.6626442670822144\n",
      "473 6.334583759307861\n",
      "474 4.25417947769165\n",
      "475 0.4562179744243622\n",
      "476 0.8384400010108948\n",
      "477 4.555547714233398\n",
      "478 1.3302334547042847\n",
      "479 1.3083593845367432\n",
      "480 5.247150421142578\n",
      "481 0.6895325183868408\n",
      "482 0.7318881750106812\n",
      "483 1.7252057790756226\n",
      "484 1.6306748390197754\n",
      "485 0.6813036203384399\n",
      "486 0.5555894374847412\n",
      "487 0.942410409450531\n",
      "488 1.6258291006088257\n",
      "489 0.4619322419166565\n",
      "490 0.5653141140937805\n",
      "491 0.3072023391723633\n",
      "492 0.3765360713005066\n",
      "493 0.7254260778427124\n",
      "494 0.35911741852760315\n",
      "495 0.28683480620384216\n",
      "496 0.7593917846679688\n",
      "497 0.46833083033561707\n",
      "498 0.654269814491272\n",
      "499 1.3123502731323242\n"
     ]
    }
   ],
   "source": [
    "#PyTorch: Control Flow + Weight Sharing\n",
    "\n",
    "    #作为动态图和权重共享的一个例子，我们实现了一个非常奇怪的模型：\n",
    "    #一个完全连接的ReLU网络，在每个前向传递中选择1到4之间的随机数并使用\n",
    "    #那么多隐藏层，重复使用相同的权重多次 计算最里面的隐藏层。\n",
    "    \n",
    "# Code in file nn/dynamic_net.py\n",
    "import random\n",
    "import torch\n",
    " \n",
    "class DynamicNet(torch.nn.Module):\n",
    "  def __init__(self, D_in, H, D_out):\n",
    "    \"\"\"\n",
    "    In the constructor we construct three nn.Linear instances that we will use\n",
    "    in the forward pass.\n",
    "    \"\"\"\n",
    "    super(DynamicNet, self).__init__()\n",
    "    self.input_linear = torch.nn.Linear(D_in, H)\n",
    "    self.middle_linear = torch.nn.Linear(H, H)\n",
    "    self.output_linear = torch.nn.Linear(H, D_out)\n",
    " \n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "    and reuse the middle_linear Module that many times to compute hidden layer\n",
    "    representations.\n",
    " \n",
    "    Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "    Python control-flow operators like loops or conditional statements when\n",
    "    defining the forward pass of the model.\n",
    " \n",
    "    Here we also see that it is perfectly safe to reuse the same Module many\n",
    "    times when defining a computational graph. This is a big improvement from Lua\n",
    "    Torch, where each Module could be used only once.\n",
    "    \"\"\"\n",
    "    h_relu = self.input_linear(x).clamp(min=0)\n",
    "    for _ in range(random.randint(0, 3)):\n",
    "      h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "    y_pred = self.output_linear(h_relu)\n",
    "    return y_pred\n",
    " \n",
    " \n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    " \n",
    "# Create random Tensors to hold inputs and outputs.\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    " \n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    " \n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(500):\n",
    "  # Forward pass: Compute predicted y by passing x to the model\n",
    "  y_pred = model(x)\n",
    " \n",
    "  # Compute and print loss\n",
    "  loss = criterion(y_pred, y)\n",
    "  print(t, loss.item())\n",
    " \n",
    "  # Zero gradients, perform a backward pass, and update the weights.\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,     1] loss: 0.001\n",
      "[1,   201] loss: 0.230\n",
      "[1,   401] loss: 0.230\n",
      "[1,   601] loss: 0.230\n",
      "[1,   801] loss: 0.228\n",
      "[1,  1001] loss: 0.225\n",
      "[1,  1201] loss: 0.218\n",
      "[1,  1401] loss: 0.209\n",
      "[1,  1601] loss: 0.204\n",
      "[1,  1801] loss: 0.203\n",
      "[1,  2001] loss: 0.195\n",
      "[1,  2201] loss: 0.193\n",
      "[1,  2401] loss: 0.195\n",
      "[1,  2601] loss: 0.194\n",
      "[1,  2801] loss: 0.189\n",
      "[1,  3001] loss: 0.182\n",
      "[1,  3201] loss: 0.186\n",
      "[1,  3401] loss: 0.181\n",
      "[1,  3601] loss: 0.174\n",
      "[1,  3801] loss: 0.173\n",
      "[1,  4001] loss: 0.177\n",
      "[1,  4201] loss: 0.174\n",
      "[1,  4401] loss: 0.174\n",
      "[1,  4601] loss: 0.166\n",
      "[1,  4801] loss: 0.162\n",
      "[1,  5001] loss: 0.167\n",
      "[1,  5201] loss: 0.162\n",
      "[1,  5401] loss: 0.167\n",
      "[1,  5601] loss: 0.167\n",
      "[1,  5801] loss: 0.159\n",
      "[1,  6001] loss: 0.157\n",
      "[1,  6201] loss: 0.159\n",
      "[1,  6401] loss: 0.155\n",
      "[1,  6601] loss: 0.163\n",
      "[1,  6801] loss: 0.161\n",
      "[1,  7001] loss: 0.154\n",
      "[1,  7201] loss: 0.159\n",
      "[1,  7401] loss: 0.149\n",
      "[1,  7601] loss: 0.160\n",
      "[1,  7801] loss: 0.157\n",
      "[1,  8001] loss: 0.156\n",
      "[1,  8201] loss: 0.154\n",
      "[1,  8401] loss: 0.154\n",
      "[1,  8601] loss: 0.144\n",
      "[1,  8801] loss: 0.152\n",
      "[1,  9001] loss: 0.147\n",
      "[1,  9201] loss: 0.153\n",
      "[1,  9401] loss: 0.156\n",
      "[1,  9601] loss: 0.143\n",
      "[1,  9801] loss: 0.154\n",
      "[1, 10001] loss: 0.149\n",
      "[1, 10201] loss: 0.148\n",
      "[1, 10401] loss: 0.149\n",
      "[1, 10601] loss: 0.149\n",
      "[1, 10801] loss: 0.145\n",
      "[1, 11001] loss: 0.148\n",
      "[1, 11201] loss: 0.143\n",
      "[1, 11401] loss: 0.145\n",
      "[1, 11601] loss: 0.147\n",
      "[1, 11801] loss: 0.139\n",
      "[1, 12001] loss: 0.143\n",
      "[1, 12201] loss: 0.144\n",
      "[1, 12401] loss: 0.142\n",
      "[2,     1] loss: 0.001\n",
      "[2,   201] loss: 0.145\n",
      "[2,   401] loss: 0.142\n",
      "[2,   601] loss: 0.146\n",
      "[2,   801] loss: 0.136\n",
      "[2,  1001] loss: 0.138\n",
      "[2,  1201] loss: 0.142\n",
      "[2,  1401] loss: 0.131\n",
      "[2,  1601] loss: 0.139\n",
      "[2,  1801] loss: 0.131\n",
      "[2,  2001] loss: 0.132\n",
      "[2,  2201] loss: 0.138\n",
      "[2,  2401] loss: 0.140\n",
      "[2,  2601] loss: 0.135\n",
      "[2,  2801] loss: 0.132\n",
      "[2,  3001] loss: 0.140\n",
      "[2,  3201] loss: 0.137\n",
      "[2,  3401] loss: 0.135\n",
      "[2,  3601] loss: 0.137\n",
      "[2,  3801] loss: 0.132\n",
      "[2,  4001] loss: 0.139\n",
      "[2,  4201] loss: 0.135\n",
      "[2,  4401] loss: 0.137\n",
      "[2,  4601] loss: 0.131\n",
      "[2,  4801] loss: 0.129\n",
      "[2,  5001] loss: 0.131\n",
      "[2,  5201] loss: 0.135\n",
      "[2,  5401] loss: 0.136\n",
      "[2,  5601] loss: 0.135\n",
      "[2,  5801] loss: 0.128\n",
      "[2,  6001] loss: 0.136\n",
      "[2,  6201] loss: 0.130\n",
      "[2,  6401] loss: 0.133\n",
      "[2,  6601] loss: 0.143\n",
      "[2,  6801] loss: 0.129\n",
      "[2,  7001] loss: 0.132\n",
      "[2,  7201] loss: 0.130\n",
      "[2,  7401] loss: 0.140\n",
      "[2,  7601] loss: 0.132\n",
      "[2,  7801] loss: 0.125\n",
      "[2,  8001] loss: 0.132\n",
      "[2,  8201] loss: 0.130\n",
      "[2,  8401] loss: 0.137\n",
      "[2,  8601] loss: 0.126\n",
      "[2,  8801] loss: 0.130\n",
      "[2,  9001] loss: 0.130\n",
      "[2,  9201] loss: 0.128\n",
      "[2,  9401] loss: 0.124\n",
      "[2,  9601] loss: 0.136\n",
      "[2,  9801] loss: 0.128\n",
      "[2, 10001] loss: 0.129\n",
      "[2, 10201] loss: 0.134\n",
      "[2, 10401] loss: 0.128\n",
      "[2, 10601] loss: 0.131\n",
      "[2, 10801] loss: 0.133\n",
      "[2, 11001] loss: 0.128\n",
      "[2, 11201] loss: 0.131\n",
      "[2, 11401] loss: 0.124\n",
      "[2, 11601] loss: 0.127\n",
      "[2, 11801] loss: 0.129\n",
      "[2, 12001] loss: 0.129\n",
      "[2, 12201] loss: 0.133\n",
      "[2, 12401] loss: 0.134\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "#https://www.jianshu.com/p/3963b2cdd771\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"docstring for Net\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)        \n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1,16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#声明使用交叉熵函数作为代价函数\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n",
    "#声明使用学习率0.001的SGD优化器\n",
    "\n",
    "for epoch in range(2):\n",
    "    running_loss = 0\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels = data\n",
    "        inputs,labels = Variable(inputs),Variable(labels)\n",
    "        #获得数据并将其放在GPU上\n",
    "        optimizer.zero_grad()\n",
    "        #初始化梯度\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        #前馈\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #反馈计算梯度并更新权值\n",
    "\n",
    "        running_loss += loss.item()    #error:    loss.data[0]\n",
    "        if i % 200 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0\n",
    "            #打印平均代价函数值\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "corret,total = 0,0\n",
    "for images,labels in testloader:\n",
    "    images = images\n",
    "    labels = labels\n",
    "    outputs = net(Variable(images))\n",
    "    _,predicted = torch.max(outputs.data,1)\n",
    "    total += labels.size(0)\n",
    "    corret += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * corret / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2345, 0.6745, 1.1587],\n",
      "        [1.0616, 1.4417, 1.3022],\n",
      "        [1.2783, 0.1463, 0.4098],\n",
      "        [0.9364, 0.8576, 0.9126],\n",
      "        [0.6517, 1.3815, 0.9280]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "x = t.rand(5,3)\n",
    "y = t.rand(5,3)\n",
    "if t.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
